{
    "docs": [
        {
            "location": "/", 
            "text": "This documentation describes the key concepts and then provides the conventions and guidelines for development of\nthe framework for \nS\ntrategies to \nIN\ntegrate\n\nD\nata and \nB\niogeochemic\nA\nl\nmo\nD\nels (SINDBAD).\n\n\nThe SINDBAD framework provides a seamless integration of model and\nmultiple data streams using different optimization schemes.\n\n\nDevelopers\n\n\nSINDBAD is being developed at the Department of Biogeochemical Integration of the Max Planck Institute for Biogeochemistry in Jena, Germany. Following is the list of SINDBAD developers.\n\n\n\n\n\n\nNuno Carvalhais (\n)\n\n\n\n\n\n\nMartin Jung (\n)\n\n\n\n\n\n\nSujan Koirala (\n)\n\n\n\n\n\n\nTina Trautmann (\n)", 
            "title": "About SINDBAD"
        }, 
        {
            "location": "/#developers", 
            "text": "SINDBAD is being developed at the Department of Biogeochemical Integration of the Max Planck Institute for Biogeochemistry in Jena, Germany. Following is the list of SINDBAD developers.    Nuno Carvalhais ( )    Martin Jung ( )    Sujan Koirala ( )    Tina Trautmann ( )", 
            "title": "Developers"
        }, 
        {
            "location": "/access/", 
            "text": "SINDBAD Repository\n\n\n\n\n\n\nSINDBAD is \nnot an open source modeling framework\n, and it is\n    available only to the members of the Department of Biogeochemical\n    Integration at the Max Planck Institute for Biogeochemistry in Jena,\n    Germany.\n\n\n\n\n\n\nSINDBAD is hosted in the git repository system (gitLab) of the\n    MPI-BGC at\n\n\n\n\nhttps://git.bgc-jena.mpg.de/sindbad/sindbad\n\n\n\n\n\n\n\n\nIn case you do not have a gitLab account, contact\n    git@bgc-jena.mpg.de to register for an account.\n\n\n\n\n\n\nFor access to the SINDBAD repository, contact either Sujan Koirala\n    (\n), Martin Jung (\n),\n    or Nuno Carvalhais (\n).\n\n\n\n\n\n\nFirst Steps\n\n\nOnce there is an access to the repository, \neveryone (users and\ndevelopers) should create a development branch from the master. The\nbranch should have a unique and logical name associated with the project\nor a person.\n\n\n\n\n\n\nThe SINDBAD code under development should only be pushed to each\n    \nperson/project's own development branch\n.\n\n\n\n\n\n\nOnce the development has been tested thoroughly, a merge request to\n    the master branch should be created.\n\n\n\n\nMerge requests to the master branch will be handled by masters\n    of the repository.\n\n\n\n\n\n\n\n\nAny one, who is new to git is highly recommended to go through the\n    basic tutorials.\n\n\n\n\n\n\nAn example of a good tutorial is at\n    \nhttps://tutorialzine.com/2016/06/learn-git-in-30-minutes\n\n\n\n\n\n\nIn some cases, beginner's tutorial course for git is provided by\n    Fabian Gans (\n) and/or Thomas Wutzler\n    (\n) at the BGI department. Check the\n    presentations in the following directory and contact them\n    directly for further possibilities.\n\n\n\n\n/Net/Groups/BGI/department/Courses/git\n\n\n\n\n\n\n\n\n\n\n\n\nSoftware Recommendations\n\n\nFollowing are some recommendations for editor and git softwares.\n\n\n\n\n\n\nCommand line with gitHub desktop (free)\n\n\n\n\n\n\ngitKraken (commercial or free for 12 months for github students\n        account)\n\n\n\n\n\n\nSourcetree (proprietary)\n\n\n\n\n\n\nThe integrated development editor 'atom', which is available for\n        all operating systems.\n\n\n\n\n\n\nCan be downloaded from \nhttps://atom.io\n.\n\n\n\n\n\n\nAtom provides inbuilt git integration. There are several\n        tutorials for git integration in atom. The example below is\n        recommended because.... ;-)\n\n\n\n\nhttps://www.youtube.com/watch?v=duQwcAEV4hk", 
            "title": "Accessing SINDBAD"
        }, 
        {
            "location": "/access/#sindbad-repository", 
            "text": "SINDBAD is  not an open source modeling framework , and it is\n    available only to the members of the Department of Biogeochemical\n    Integration at the Max Planck Institute for Biogeochemistry in Jena,\n    Germany.    SINDBAD is hosted in the git repository system (gitLab) of the\n    MPI-BGC at   https://git.bgc-jena.mpg.de/sindbad/sindbad     In case you do not have a gitLab account, contact\n    git@bgc-jena.mpg.de to register for an account.    For access to the SINDBAD repository, contact either Sujan Koirala\n    ( ), Martin Jung ( ),\n    or Nuno Carvalhais ( ).", 
            "title": "SINDBAD Repository"
        }, 
        {
            "location": "/access/#first-steps", 
            "text": "Once there is an access to the repository,  everyone (users and\ndevelopers) should create a development branch from the master. The\nbranch should have a unique and logical name associated with the project\nor a person.    The SINDBAD code under development should only be pushed to each\n     person/project's own development branch .    Once the development has been tested thoroughly, a merge request to\n    the master branch should be created.   Merge requests to the master branch will be handled by masters\n    of the repository.     Any one, who is new to git is highly recommended to go through the\n    basic tutorials.    An example of a good tutorial is at\n     https://tutorialzine.com/2016/06/learn-git-in-30-minutes    In some cases, beginner's tutorial course for git is provided by\n    Fabian Gans ( ) and/or Thomas Wutzler\n    ( ) at the BGI department. Check the\n    presentations in the following directory and contact them\n    directly for further possibilities.   /Net/Groups/BGI/department/Courses/git", 
            "title": "First Steps"
        }, 
        {
            "location": "/access/#software-recommendations", 
            "text": "Following are some recommendations for editor and git softwares.    Command line with gitHub desktop (free)    gitKraken (commercial or free for 12 months for github students\n        account)    Sourcetree (proprietary)    The integrated development editor 'atom', which is available for\n        all operating systems.    Can be downloaded from  https://atom.io .    Atom provides inbuilt git integration. There are several\n        tutorials for git integration in atom. The example below is\n        recommended because.... ;-)   https://www.youtube.com/watch?v=duQwcAEV4hk", 
            "title": "Software Recommendations"
        }, 
        {
            "location": "/concept/", 
            "text": "Figure: A simple schematic of main SINDBAD components and conceptual flow (dotted arrows are the functional calls)\n\n\nSINDBAD Concepts\n\n\nThe SINDBAD framework provides a seamless integration of model and multiple data streams using different optimization schemes. For that, modularity regarding model structure, input/output handling and model optimization are key. These information on selected approaches and options are provided through configuration files, and they are stored in a consistent way in different SINDBAD objects and structures, so that the model technically always sees the same information. Fundamentally, SINDBAD consists of the following components:\n\n\ninfo\n\n\n\n\nThe info is essentially the brain of SINDBAD.\n\n\nTechnically, it is a structure that stores all the information needed to read the data, run and/or optimize the model, and processthe output.\n\n\nThis information together defines the experimental setup\n    and are read and processed from different configuration files.\n\n\n\n\nTEM\n\n\n\n\n\n\nTEM stands for Terrestrial Ecosystem Model, and provides functionalities for running the model in several modes, such as for spinup, forward run, precomputation, etc.\n\n\n\n\n\n\nTEM includes four functions:\n\n\n\n\n\n\nrunTEM\n: The main function that runs the precomputation, spinup. Both these functions execute coreTEM.\n\n\n\n\n\n\nrunPrecOnceTEM\n: Runs the precomputation \"once\". It refers to precomputations that do not need to be redone in every iteration of optimization because the outcome is independent of the optimized parameter(s).\n\n\n\n\n\n\nrunSpinupTEM\n: Runs the model in spinup mode. Only the subset of modules that are needed for the spinup are run. Unlike precomputations, the spin up is redone every time in optimization.\n\n\n\n\n\n\nrunCoreTEM\n: Runs the coreTEM.\n\n\n\n\n\n\n\n\n\n\nThe information about 'how' to run the TEM in different modes are parsed through the configuration files.\n\n\n\n\n\n\nDifferent modes of model run are inferred from the set of inputs that are passed while calling \nrunTEM\n in \nworkflowTEM.m\n.\n\n\n\n\n\n\nDo not rename or edit the functions in the tem directory. If needed, consult the SINDBAD development team.\n\n\n\n\n\n\ncore\n\n\n\n\nThe core driver which loops over time and executes all the selected approaches for biogeochemical processes.\n\n\n\n\nBy design,the core can be modified by anyone to accommodate different ways to run the modules, e.g., different orders of modules, implicit time steps, etc.\n\n\n\n\n\n\nThe default core is named coreTEM.m.\n\n\n\n\n\n\nNever change/edit the default core.\n\n\n\n\nIn case the core is modified, a copy of the \ncoreTEM.m\n should be created.\n\n\nAlways follow a logical naming for the core such as \ncoreTEM_experiment.m\n.\n\n\nTo use the modified core, the path to the core for an experiment has to be changed in the \nmodelStructure[.json]\n configuration file.\n\n\n\n\n\n\n\n\nmodule\n\n\nThe overarching process, response, or a variable that may be parameterized using different approaches, e.g., surface runoff or GPP. A module consists of different approaches.\n\n\napproach\n\n\nA representation or a calculation function of one process, response, or a variable. For example, a function that calculates surface runoff using overflow method, or an equation to calculate GPP as a function of global radiation.\n\n\n\n\nCarefully read and strictly follow the conventions on modules and approaches\n that are provided in the latter sections of this convention.\n\n\n\n\nexperiment\n\n\n\n\nA set-up of a model simulation with a given forcing, parameter, optimization scheme, spinup, forward run, etc.\n\n\nThe configuration files for each of the above steps should be provided in the \nexperiment*[.json]\n.\n\n\n\n\nmodel structure\n\n\n\n\nA set of information spanning selected modules and approaches from coreTEM with an associated core (i.e. sequence of modules, possibly nested time loops etc.). \n\n\nIn the info, the fields related to model structure are identified by the string 'ms'.\n\n\n\n\nprecomputation\n\n\n\n\nPrecomputation refers to computations of the core that can be executed outside the time loop. Essentially, these calculations are independent of state variables.\n\n\nPrecomputations are particularly beneficial in terms of computational performance for a single time series or small spatial domains.\n\n\n\n\nPrecomputations are being separated automatically into \"once\" and \"always\".\n\n\n\n\n\"Once\" refers to precomputations that do not need to be done in every iteration of optimization because the outcome is independent of the optimized parameter(s).\n\n\n\"Always\" refers to precomputations that need to be done in every iteration of optimization because the outcome depends on optimized parameter(s). precAlways is executed every time the core is called, but outside the time loop.\n\n\n\n\n\n\n\n\nPrecomputation is represented by the string 'prec' throughout the code, info, and configuration files.\n\n\n\n\n\n\ngenerated code\n\n\n\n\nThe generated code refers to the parsed matlab function that puts together all the executable code from all functional calls in the core.\n\n\nGiven the options, the code for precomputation and the dynamic (core) are generated for forward run and spinup.\n\n\nThe options in configuration and the fields of info related to code generation are identified by the string 'gen'.\n\n\nThe execution time for generated core is usually faster than raw model.\n\n\nIn order for code generation to be correct, all conventions on variables and fields of the SINDBAD structures need to be strictly followed.\n\n\n\n\nreduced memory\n\n\n\n\n\n\nReduced memory (redMem in configuration and info) refers to the execution of the model in a memory-efficient manner.\n\n\n\n\n\n\nThis mode is designed for simulations when the full time series of a variable is not needed.\n\n\n\n\n\n\nIn this mode, all the variables that are not needed to be \"stored\" (see output configuration file) will be automatically changed to size \nnPix\n,1 instead of \nnPix,nTix\n sized arrays. This will significantly reduce the memory load of the model. \n\n\n\n\nNote that this feature is only available while running the generated code.", 
            "title": "Concept & Definitions"
        }, 
        {
            "location": "/concept/#sindbad-concepts", 
            "text": "The SINDBAD framework provides a seamless integration of model and multiple data streams using different optimization schemes. For that, modularity regarding model structure, input/output handling and model optimization are key. These information on selected approaches and options are provided through configuration files, and they are stored in a consistent way in different SINDBAD objects and structures, so that the model technically always sees the same information. Fundamentally, SINDBAD consists of the following components:", 
            "title": "SINDBAD Concepts"
        }, 
        {
            "location": "/concept/#info", 
            "text": "The info is essentially the brain of SINDBAD.  Technically, it is a structure that stores all the information needed to read the data, run and/or optimize the model, and processthe output.  This information together defines the experimental setup\n    and are read and processed from different configuration files.", 
            "title": "info"
        }, 
        {
            "location": "/concept/#tem", 
            "text": "TEM stands for Terrestrial Ecosystem Model, and provides functionalities for running the model in several modes, such as for spinup, forward run, precomputation, etc.    TEM includes four functions:    runTEM : The main function that runs the precomputation, spinup. Both these functions execute coreTEM.    runPrecOnceTEM : Runs the precomputation \"once\". It refers to precomputations that do not need to be redone in every iteration of optimization because the outcome is independent of the optimized parameter(s).    runSpinupTEM : Runs the model in spinup mode. Only the subset of modules that are needed for the spinup are run. Unlike precomputations, the spin up is redone every time in optimization.    runCoreTEM : Runs the coreTEM.      The information about 'how' to run the TEM in different modes are parsed through the configuration files.    Different modes of model run are inferred from the set of inputs that are passed while calling  runTEM  in  workflowTEM.m .    Do not rename or edit the functions in the tem directory. If needed, consult the SINDBAD development team.", 
            "title": "TEM"
        }, 
        {
            "location": "/concept/#core", 
            "text": "The core driver which loops over time and executes all the selected approaches for biogeochemical processes.   By design,the core can be modified by anyone to accommodate different ways to run the modules, e.g., different orders of modules, implicit time steps, etc.    The default core is named coreTEM.m.    Never change/edit the default core.   In case the core is modified, a copy of the  coreTEM.m  should be created.  Always follow a logical naming for the core such as  coreTEM_experiment.m .  To use the modified core, the path to the core for an experiment has to be changed in the  modelStructure[.json]  configuration file.", 
            "title": "core"
        }, 
        {
            "location": "/concept/#module", 
            "text": "The overarching process, response, or a variable that may be parameterized using different approaches, e.g., surface runoff or GPP. A module consists of different approaches.", 
            "title": "module"
        }, 
        {
            "location": "/concept/#approach", 
            "text": "A representation or a calculation function of one process, response, or a variable. For example, a function that calculates surface runoff using overflow method, or an equation to calculate GPP as a function of global radiation.   Carefully read and strictly follow the conventions on modules and approaches  that are provided in the latter sections of this convention.", 
            "title": "approach"
        }, 
        {
            "location": "/concept/#experiment", 
            "text": "A set-up of a model simulation with a given forcing, parameter, optimization scheme, spinup, forward run, etc.  The configuration files for each of the above steps should be provided in the  experiment*[.json] .", 
            "title": "experiment"
        }, 
        {
            "location": "/concept/#model-structure", 
            "text": "A set of information spanning selected modules and approaches from coreTEM with an associated core (i.e. sequence of modules, possibly nested time loops etc.).   In the info, the fields related to model structure are identified by the string 'ms'.", 
            "title": "model structure"
        }, 
        {
            "location": "/concept/#precomputation", 
            "text": "Precomputation refers to computations of the core that can be executed outside the time loop. Essentially, these calculations are independent of state variables.  Precomputations are particularly beneficial in terms of computational performance for a single time series or small spatial domains.   Precomputations are being separated automatically into \"once\" and \"always\".   \"Once\" refers to precomputations that do not need to be done in every iteration of optimization because the outcome is independent of the optimized parameter(s).  \"Always\" refers to precomputations that need to be done in every iteration of optimization because the outcome depends on optimized parameter(s). precAlways is executed every time the core is called, but outside the time loop.     Precomputation is represented by the string 'prec' throughout the code, info, and configuration files.", 
            "title": "precomputation"
        }, 
        {
            "location": "/concept/#generated-code", 
            "text": "The generated code refers to the parsed matlab function that puts together all the executable code from all functional calls in the core.  Given the options, the code for precomputation and the dynamic (core) are generated for forward run and spinup.  The options in configuration and the fields of info related to code generation are identified by the string 'gen'.  The execution time for generated core is usually faster than raw model.  In order for code generation to be correct, all conventions on variables and fields of the SINDBAD structures need to be strictly followed.", 
            "title": "generated code"
        }, 
        {
            "location": "/concept/#reduced-memory", 
            "text": "Reduced memory (redMem in configuration and info) refers to the execution of the model in a memory-efficient manner.    This mode is designed for simulations when the full time series of a variable is not needed.    In this mode, all the variables that are not needed to be \"stored\" (see output configuration file) will be automatically changed to size  nPix ,1 instead of  nPix,nTix  sized arrays. This will significantly reduce the memory load of the model.    Note that this feature is only available while running the generated code.", 
            "title": "reduced memory"
        }, 
        {
            "location": "/info/", 
            "text": "What is the info?\n\n\nThe info is essentially the brain of SINDBAD. Technically, it is a\nstructure that stores all the information needed to read the data, run\nand/or optimize the model, and process the output based on an\nexperimental setup that is provided by different configuration files.\n\n\nThe main fields\n\n\nThe main fields or branches of the info structure are as follows:\n\n\n\n\n\n\nexperiment\n: name, domain, version, user, date of running, full\n    paths of all other configuration files (forcing, model structure,\n    constants (physical), model run, output, and optimization (optional)\n\n\n\n\n\n\ntem\n: information on model, forcing, parameters, spinup runs,\n    etc.\n\n\n\n\n\n\nopti\n: all Information related to optimization including cost\n    function, optimization method, data constraints, parameters, etc.\n\n\n\n\n\n\npostProcess:\n post processing information such as spatial and\n    temporal aggregations, metric calculations, etc.\n\n\n\n\n\n\n\n\nFigure: An overview of SINDBAD info. An interactive representation of the full info is available at:\n\n\nhttp://intra.bgc-jena.mpg.de/bgi/projects/sindbad/graphs/sindbad_info/inforad.html\n\n\nConventions on info\n\n\nThe conventions for different fields of info are as follows:\n\n\n\n\n\n\nflags:\n all information that goes into flags field can only take\n    two values: 0 and 1. As such, the flags should only be used for\n    True/False, On/Off cases.\n\n\n\n\n\n\npaths:\n all paths variables should point to the absolute path of\n    the file. Note that this will be platform (for access to network\n    drive)- and machine (for access to local drive)- dependent.\n\n\n\n\n\n\nvariables:\n all values in the variables field of info should\n    contain a list.\n\n\n\n\nFor example, \nvariables.to.store\n should be a list of variables\n    to be stored in the memory.\n\n\n\n\n\n\n\n\nThe fields listed above can be different subfields of the info at\n    different depths depending on their association with the main field.\n    Thus, they should always be inferred with respect to higher level\n    fields.\n\n\n\n\nFor example, a field called \n.flags\n can be inside \ntem.model\n\n    or \ntem.spinup\n. The first set of flags is for model run, and\n    second set is for spinup.", 
            "title": "SINDBAD info"
        }, 
        {
            "location": "/info/#what-is-the-info", 
            "text": "The info is essentially the brain of SINDBAD. Technically, it is a\nstructure that stores all the information needed to read the data, run\nand/or optimize the model, and process the output based on an\nexperimental setup that is provided by different configuration files.", 
            "title": "What is the info?"
        }, 
        {
            "location": "/info/#the-main-fields", 
            "text": "The main fields or branches of the info structure are as follows:    experiment : name, domain, version, user, date of running, full\n    paths of all other configuration files (forcing, model structure,\n    constants (physical), model run, output, and optimization (optional)    tem : information on model, forcing, parameters, spinup runs,\n    etc.    opti : all Information related to optimization including cost\n    function, optimization method, data constraints, parameters, etc.    postProcess:  post processing information such as spatial and\n    temporal aggregations, metric calculations, etc.     Figure: An overview of SINDBAD info. An interactive representation of the full info is available at:  http://intra.bgc-jena.mpg.de/bgi/projects/sindbad/graphs/sindbad_info/inforad.html", 
            "title": "The main fields"
        }, 
        {
            "location": "/info/#conventions-on-info", 
            "text": "The conventions for different fields of info are as follows:    flags:  all information that goes into flags field can only take\n    two values: 0 and 1. As such, the flags should only be used for\n    True/False, On/Off cases.    paths:  all paths variables should point to the absolute path of\n    the file. Note that this will be platform (for access to network\n    drive)- and machine (for access to local drive)- dependent.    variables:  all values in the variables field of info should\n    contain a list.   For example,  variables.to.store  should be a list of variables\n    to be stored in the memory.     The fields listed above can be different subfields of the info at\n    different depths depending on their association with the main field.\n    Thus, they should always be inferred with respect to higher level\n    fields.   For example, a field called  .flags  can be inside  tem.model \n    or  tem.spinup . The first set of flags is for model run, and\n    second set is for spinup.", 
            "title": "Conventions on info"
        }, 
        {
            "location": "/structures/", 
            "text": "What are SINDBAD Structures?\n\n\nBesides the info, all other variables and information needed to execute\nthe experiment and run the TEM are stored in different structures as\nwell. These structures and their corresponding conventions are explained\nbelow. To enable modularity of the TEM, all approaches are called with\nthe info, and the same set of SINDBAD structures (with time step, tix,\nbeing the difference between precomputed and dynamic parts of an\napproach; see the conventions for approaches). The variables and data\nneeded within each approach are extracted from these structures. An\noverview of the structures is provided in Table 1. All developers are\nstrongly recommended to read the full explanation, as well.\n\n\nTable 1. An overview of the SINDBAD structures\n\n\n\n\n\n\n\n\nName\n\n\nWhat?\n\n\nSize\n\n\nMain Convention\n\n\nSpecial Fields*\n\n\n\n\n\n\n\n\n\n\nf\n\n\nForcing climate variables\n\n\nnPix,nTix\n\n\nf.[VarName]\n\n\n\n\n\n\n\n\nfe\n\n\nExtra forcings, precomputations\n\n\nnPix,nTix\n\n\nfe.[ModuleName].[VarName]\n\n\n\n\n\n\n\n\nfx\n\n\nFluxes\n\n\nnPix,nTix\n\n\nfx.[VarName]\n\n\n\n\n\n\n\n\ns\n\n\nState variables, state dependent parameters in s.cd.p_*, etc.\n\n\nnPix,nZix\n\n\ns.c.c[VarName], s.cd.[VarName], s.w.w[VarName], s.wd.[VarName]\n\n\ns.prev\n\n\n\n\n\n\nd\n\n\nDiagnostics\n\n\nnPix,nTix\n\n\nd.[ModuleName].[VarName]\n\n\nd.prev, d.storedStates\n\n\n\n\n\n\np\n\n\nParameters\n\n\nnPix,1 or a scalar\n\n\np.[ModuleName].[VarName]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n*Can have different sizes of array compared to other variables in the same structure. Can include objects that cannot strictly be categorized into a specifice structure.\n\n\nForcing (f)\n\n\nThe 'f' stores the forcing variables related to climate.\n\n\n\n\n\n\nThe forcing variables are stored as *f.[VarName]. *\n\n\n\n\n\n\nThe size of a forcing variable is \nnPix,nTix\n.\n\n\n\n\n\n\nAll other forcings, that are not purely climatic, should be\n    stored in s, fe, and d. For example, leaf area index\n    (LAI)/fraction of Photosynthetically Active Radiation (fPAR),\n    that may be forced, should be copied to s.cd.LAI or s.cd.fPAR.\n    This allows for flexibility of either getting the variable from\n    forcing or calculating them prognostically.\n\n\n\n\n\n\nExtra Forcing (fe)\n\n\nThe 'fe' stores the pre-computed 'extra forcing'.\n\n\n\n\n\n\nThese are the variables within an approach that are independent\n    of the state variables and can be calculated using vector\n    operations outside the time loop. For example:\n\n\n\n\n\n\nPotential variables that are only dependent on climate\n    forcing, e.g., potential snowmelt, potential\n    evapotranspiration.\n\n\n\n\n\n\nStressors (scalars) that are exclusively computed in\n    precomputations from forcing. For example, scaled snowfall,\n    if the scaling factor is not optimized.\n\n\n\n\n\n\n\n\n\n\nEssentially, the variables in \nfe\n are intermediate\n    calculations that are used when the state dependent variables\n    are calculated. Therefore, they do not always have meanings and\n    may be cryptic:\n\n\n\n\n\n\nA numerical array which is used for calculating some other\n    variable.\n\n\n\n\n\n\nThe product of all stressors (water effect, light effect,\n    etc.).\n\n\n\n\n\n\n\n\n\n\nThe variables are stored in \nfe\n as\n\n\n\n\n\n\nfe.[ModuleName].[Variable]\n\n\n\n\nThis makes sure that the precomputed extra forcing for a\n    module is under the subfield for that particular module.\n\n\n\n\n\n\n\n\nThe size of the variables in \nfe\n is \nnPix,nTix\n\n\n\n\n\n\n\n\n\n\nFluxes (fx)\n\n\nThe 'fx' stores all the flux variables.\n\n\n\n\n\n\nThe variables are added in the \nfx\n using the following\n    convention\n\n\n\n\n\n\nfx.[VarName]\n\n\n\n\n\n\nMake sure that the name of the variables added in the \nfx\n\n    structure are unique and intuitive.\n\n\n\n\n\n\n\n\n\n\nThe size for variables in \nfx\n is \nnPix,nTix\n\n\n\n\n\n\nStates (s)\n\n\nThe 's' stores the state variables that are either storage\npools or storage-related diagnostics.\n\n\n\n\n\n\nThe top-level fields in \ns\n are divided according to the\n    element of the cycle.\n\n\n\n\n\n\ns.w.[VarName]\n for water storages\n\n\n\n\n\n\ns.wd.[VarName]\n for \"diagnostic\" state variables of water\n    that are not storage, e.g., water table depth, snow cover\n    fraction\n\n\n\n\n\n\ns.c\n for carbon storages\n\n\n\n\n\n\ns.cd\n for \"diagnostic\" state variables of carbon\n\n\n\n\n\n\ncd\n and \nwd\n can also store\n\n\n\n\n\n\nthe module parameters that are dependent on states using\n    the following convention:\n\n\n\n\n\n\ns.cd.p_[ModuleName]_ParameterName\n\n\n\n\n\n\ns.wd.p_[ModuleName]_ParameterName\n\n\n\n\n\n\n\n\n\n\nthe forcing variables that are not strictly climatic.\n    For example, LAI and fPAR which can either be forced or\n    calculated prognostically should be stored in s.cd.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe variable names for each storage should always start with the\n    letter 'c' or 'w' for carbon and water storages, respectively.\n    For example, \ns.w.wSoil\n, \ns.c.cVeg\n, etc. (see variable naming\n    and conventions)\n\n\n\n\n\n\nThe variables in \ns.*.\n are either of size \nnPix,1\n or\n    \nnPix,nZix\n.\n\n\n\n\n\n\nThe variables are overwritten in every time step, and,\n    therefore, do not have time dimension.\n\n\n\n\n\n\nThe time series of storage variables are stored in\n    \nd.storedStates\n.\n\n\n\n\n\n\n\n\n\n\nLike d (see the following part), \ns\n also has a special field\n    \ns.prev.\n for storing state variables of the previous time step.\n\n\n\n\n\n\nfor carbon storages: \ns.prev_s_c_[VarName]\n\n\n\n\n\n\nfor carbon states: \ns.prev_s_cd_[VarName]\n\n\n\n\n\n\nfor water storages: \ns.prev_s_w_[VarName]\n\n\n\n\n\n\nfor water states: \ns.prev_s_wd_[VarName]\n\n\n\n\n\n\nFor \nstates\n, the size is nPix,1\n\n\n\n\n\n\nFor \nstorages\n, the size is nPix,nZix\n\n\n\n\n\n\n\n\n\n\nNote that some states that are an input (e.g., LAI) and not\nexclusively updated in the model may be stored in forcing\nstructure \nf\n.\n\n\n\n\n\n\nDiagnostics (d)\n\n\nThe 'd' stores all diagnostic variables.\n\n\n\n\n\n\nIn general, they include variables that have some meaningful\n    purposes (that would interest the users), e.g., stressors like\n    demand-driven GPP, temperature effect on GPP, water effect,\n    light effect, etc.\n\n\n\n\n\n\nnote:\n Variables that refer to states (e.g. snow cover\n    fraction) shall not be in \nd\n but in \ns\n (\ns.cd\n or \ns.wd\n)\n\n\n\n\n\n\nThe variables are stored in the \nd\n using the following\n    convention\n\n\n\n\nd.[ModuleName].[Variable]\n\n\n\n\n\n\n\n\nThe size of the variables is \nnPix,nTix\n.\n\n\n\n\n\n\nd has two special fields \n\n\n\n\n\n\nd.prev\n:\n\n\n\n\n\n\nThis is used to keep track of variables from \nf\n,\n    \nfe\n, \nfx\n and \nd\n (except those from states\n    \ns\n) from previous time step.\n\n\n\n\n\n\nAll the fields of \nd.prev.\n should have size 1 in the\n    time dimension.\n\n\n\n\n\n\nThe conventions for the field names are distinct for the\n    variables in different SINDBAD structures:\n\n\n\n\n\n\nfor forcings (\nf\n):\n\n\n\n\n\n\nd.prev.f_[ VarName]\n\n\n\n\n\n\nsize is \nnPix,1\n\n\n\n\n\n\n\n\n\n\nfor fluxes (\nfx\n):\n\n\n\n\n\n\nd.prev.fx_[VarName]\n\n\n\n\n\n\nsize is \nnPix,1\n\n\n\n\n\n\n\n\n\n\nfor extra forcing (\nfe\n) and diagnostics (\nd\n):\n\n\n\n\n\n\nd.prev.d_[ModuleName]_[VarName]\n\n\n\n\n\n\nfe.prev.fe_[ModuleName]_[VarName]\n\n\n\n\n\n\nsize is \nnPix,1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe state variables of the previous time step are stored\n    in \ns.prev.\n\n\n\n\n\n\n\n\n\n\nd.storedStates:\n\n\n\n\n\n\nstores the time series of state variables, if needed.\n    The variables in storedStates are in .\nvariablesToStore\n    and\n .\nvariablesTowrite\n.\n\n\n\n\n\n\nThe list of state variables to store are given in the\n    configuration file for output[.json] in the field\n    \nvariables.to.store\n. The variables in this field should\n    be\n\n\n\n\n\n\n*d.storedStates.[poolName] *\n\n\n\n\npoolName is the short variable name without the\n    upper fields of structure \ns\n. For example,\n    \ns.w.wSoil [nPix,nZix]\n would be stored in\n    \nd.storedStates.wSoil [nPix,nZix,nTix]\n.\n\n\n\n\n\n\n\n\nsize is \nnPix,nZix,nTix\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameters (p)\n\n\nThe 'p' stores all the parameters of the model.\n\n\n\n\n\n\nThe parameters that do not change in time are stored as:\n\n\n\n\np.[ModuleName].[VarName]\n\n\n\n\n\n\n\n\nThe scalar parameters, i.e., one value, are spatialized to\n    \nnPix,1\n in the precomputation part of the approach (module, as\n    the parameters for an approach of a module is stored in\n    p.ModuleName.) to which the parameter belongs.\n\n\n\n\n\n\nNote that the parameters that depend on the states are stored\n    in \ns.cd.p_*\n or s\n.wd.p_*\n. See the explanation for the\n    structure s for details.", 
            "title": "SINDBAD Structures"
        }, 
        {
            "location": "/structures/#what-are-sindbad-structures", 
            "text": "Besides the info, all other variables and information needed to execute\nthe experiment and run the TEM are stored in different structures as\nwell. These structures and their corresponding conventions are explained\nbelow. To enable modularity of the TEM, all approaches are called with\nthe info, and the same set of SINDBAD structures (with time step, tix,\nbeing the difference between precomputed and dynamic parts of an\napproach; see the conventions for approaches). The variables and data\nneeded within each approach are extracted from these structures. An\noverview of the structures is provided in Table 1. All developers are\nstrongly recommended to read the full explanation, as well.  Table 1. An overview of the SINDBAD structures     Name  What?  Size  Main Convention  Special Fields*      f  Forcing climate variables  nPix,nTix  f.[VarName]     fe  Extra forcings, precomputations  nPix,nTix  fe.[ModuleName].[VarName]     fx  Fluxes  nPix,nTix  fx.[VarName]     s  State variables, state dependent parameters in s.cd.p_*, etc.  nPix,nZix  s.c.c[VarName], s.cd.[VarName], s.w.w[VarName], s.wd.[VarName]  s.prev    d  Diagnostics  nPix,nTix  d.[ModuleName].[VarName]  d.prev, d.storedStates    p  Parameters  nPix,1 or a scalar  p.[ModuleName].[VarName]             *Can have different sizes of array compared to other variables in the same structure. Can include objects that cannot strictly be categorized into a specifice structure.", 
            "title": "What are SINDBAD Structures?"
        }, 
        {
            "location": "/structures/#forcing-f", 
            "text": "The 'f' stores the forcing variables related to climate.    The forcing variables are stored as *f.[VarName]. *    The size of a forcing variable is  nPix,nTix .    All other forcings, that are not purely climatic, should be\n    stored in s, fe, and d. For example, leaf area index\n    (LAI)/fraction of Photosynthetically Active Radiation (fPAR),\n    that may be forced, should be copied to s.cd.LAI or s.cd.fPAR.\n    This allows for flexibility of either getting the variable from\n    forcing or calculating them prognostically.", 
            "title": "Forcing (f)"
        }, 
        {
            "location": "/structures/#extra-forcing-fe", 
            "text": "The 'fe' stores the pre-computed 'extra forcing'.    These are the variables within an approach that are independent\n    of the state variables and can be calculated using vector\n    operations outside the time loop. For example:    Potential variables that are only dependent on climate\n    forcing, e.g., potential snowmelt, potential\n    evapotranspiration.    Stressors (scalars) that are exclusively computed in\n    precomputations from forcing. For example, scaled snowfall,\n    if the scaling factor is not optimized.      Essentially, the variables in  fe  are intermediate\n    calculations that are used when the state dependent variables\n    are calculated. Therefore, they do not always have meanings and\n    may be cryptic:    A numerical array which is used for calculating some other\n    variable.    The product of all stressors (water effect, light effect,\n    etc.).      The variables are stored in  fe  as    fe.[ModuleName].[Variable]   This makes sure that the precomputed extra forcing for a\n    module is under the subfield for that particular module.     The size of the variables in  fe  is  nPix,nTix", 
            "title": "Extra Forcing (fe)"
        }, 
        {
            "location": "/structures/#fluxes-fx", 
            "text": "The 'fx' stores all the flux variables.    The variables are added in the  fx  using the following\n    convention    fx.[VarName]    Make sure that the name of the variables added in the  fx \n    structure are unique and intuitive.      The size for variables in  fx  is  nPix,nTix", 
            "title": "Fluxes (fx)"
        }, 
        {
            "location": "/structures/#states-s", 
            "text": "The 's' stores the state variables that are either storage\npools or storage-related diagnostics.    The top-level fields in  s  are divided according to the\n    element of the cycle.    s.w.[VarName]  for water storages    s.wd.[VarName]  for \"diagnostic\" state variables of water\n    that are not storage, e.g., water table depth, snow cover\n    fraction    s.c  for carbon storages    s.cd  for \"diagnostic\" state variables of carbon    cd  and  wd  can also store    the module parameters that are dependent on states using\n    the following convention:    s.cd.p_[ModuleName]_ParameterName    s.wd.p_[ModuleName]_ParameterName      the forcing variables that are not strictly climatic.\n    For example, LAI and fPAR which can either be forced or\n    calculated prognostically should be stored in s.cd.        The variable names for each storage should always start with the\n    letter 'c' or 'w' for carbon and water storages, respectively.\n    For example,  s.w.wSoil ,  s.c.cVeg , etc. (see variable naming\n    and conventions)    The variables in  s.*.  are either of size  nPix,1  or\n     nPix,nZix .    The variables are overwritten in every time step, and,\n    therefore, do not have time dimension.    The time series of storage variables are stored in\n     d.storedStates .      Like d (see the following part),  s  also has a special field\n     s.prev.  for storing state variables of the previous time step.    for carbon storages:  s.prev_s_c_[VarName]    for carbon states:  s.prev_s_cd_[VarName]    for water storages:  s.prev_s_w_[VarName]    for water states:  s.prev_s_wd_[VarName]    For  states , the size is nPix,1    For  storages , the size is nPix,nZix      Note that some states that are an input (e.g., LAI) and not\nexclusively updated in the model may be stored in forcing\nstructure  f .", 
            "title": "States (s)"
        }, 
        {
            "location": "/structures/#diagnostics-d", 
            "text": "The 'd' stores all diagnostic variables.    In general, they include variables that have some meaningful\n    purposes (that would interest the users), e.g., stressors like\n    demand-driven GPP, temperature effect on GPP, water effect,\n    light effect, etc.    note:  Variables that refer to states (e.g. snow cover\n    fraction) shall not be in  d  but in  s  ( s.cd  or  s.wd )    The variables are stored in the  d  using the following\n    convention   d.[ModuleName].[Variable]     The size of the variables is  nPix,nTix .    d has two special fields     d.prev :    This is used to keep track of variables from  f ,\n     fe ,  fx  and  d  (except those from states\n     s ) from previous time step.    All the fields of  d.prev.  should have size 1 in the\n    time dimension.    The conventions for the field names are distinct for the\n    variables in different SINDBAD structures:    for forcings ( f ):    d.prev.f_[ VarName]    size is  nPix,1      for fluxes ( fx ):    d.prev.fx_[VarName]    size is  nPix,1      for extra forcing ( fe ) and diagnostics ( d ):    d.prev.d_[ModuleName]_[VarName]    fe.prev.fe_[ModuleName]_[VarName]    size is  nPix,1        The state variables of the previous time step are stored\n    in  s.prev.      d.storedStates:    stores the time series of state variables, if needed.\n    The variables in storedStates are in . variablesToStore\n    and  . variablesTowrite .    The list of state variables to store are given in the\n    configuration file for output[.json] in the field\n     variables.to.store . The variables in this field should\n    be    *d.storedStates.[poolName] *   poolName is the short variable name without the\n    upper fields of structure  s . For example,\n     s.w.wSoil [nPix,nZix]  would be stored in\n     d.storedStates.wSoil [nPix,nZix,nTix] .     size is  nPix,nZix,nTix", 
            "title": "Diagnostics (d)"
        }, 
        {
            "location": "/structures/#parameters-p", 
            "text": "The 'p' stores all the parameters of the model.    The parameters that do not change in time are stored as:   p.[ModuleName].[VarName]     The scalar parameters, i.e., one value, are spatialized to\n     nPix,1  in the precomputation part of the approach (module, as\n    the parameters for an approach of a module is stored in\n    p.ModuleName.) to which the parameter belongs.    Note that the parameters that depend on the states are stored\n    in  s.cd.p_*  or s .wd.p_* . See the explanation for the\n    structure s for details.", 
            "title": "Parameters (p)"
        }, 
        {
            "location": "/conventions/", 
            "text": "General\n\n\n\n\n\n\nAlways follow all the conventions in this document. In case there is\n    a question on clarification, ask an experienced developer.\n\n\n\n\n\n\nMaintain associations between function names and field names of the\n    'info'. For example,\n\n\n\n\n\n\nOptimization is abbreviated to opti in info. So, a function that\n    prepares the optimization should be prepOpti.m rather than\n    prepare_Optimization.m.\n\n\n\n\n\n\nThe model is referred to as tem. The functions that runs the\n    model is named runTEM.m rather than runModel.m.\n\n\n\n\n\n\n\n\n\n\nConsider the perspective of \"someone else\" who needs to \"modify how\"\n    things are done with respect to \"something\"; i.e., tangibility of\n    the variables, function names, and so on.\n\n\n\n\n\n\nFor example,\n\n\n\n\n\n\na function calculates the outflow for a pool based on\n    different mathematical formulations. If the output flux is\n    say baseflow (Qbase) from groundwater (wGW) storage. For a\n    linear function, use the name Qbase_linwGW.m\n\n\n\n\n\n\nA variable should be named in a way that explains what is\n    being done. For GPP as a function of Tair should be GPPfTair\n    = ....\n\n\n\n\n\n\n\n\n\n\nfor making the code intuitive and maintaining the integrity of\n    the model.\n\n\n\n\n\n\n\n\n\n\nAlways report inconsistencies, bugs, and error in the code to the\n    development team.\n\n\n\n\nThis should always be done by creating an issue in gitLab.\n\n\n\n\n\n\n\n\nVariables\n\n\n\n\n\n\nThe state variables of an element are identified with the\n    starting letter of the element at the beginning of a variable\n    name. 'c' and 'w' are used for carbon and water state variables,\n    respectively.\n\n\n\n\nFor example, soil moisture storage is name \nwSoil\n.\n    Vegetation carbon pool is represented as \ncVeg\n.\n\n\n\n\n\n\n\n\nAll the water storages are represented by \nwPools\n.\n\n\n\n\n\n\nAll the carbon pools are represented by a single variable\n    \ncEco\n, which may contain \ncVeg\n, \ncRoot\n, and so on.\n\n\n\n\n\n\nNote that cEco is not the total carbon storage. It is a\n    variable that has all the component pools in one array. For\n    example, if there are 14 pools (nZix) and 1000 pixels\n    (nPix), the size of cEco for 1 time step is 1000,14,1.\n\n\n\n\n\n\nThis variable is only generated when combinePools option is\n    set to true in modelStructure[.json] configuration file.\n\n\n\n\n\n\n\n\n\n\nThe time index is represented by \ntix\n.\n\n\n\n\n\n\nThe space index is represented by \npix\n.\n\n\n\n\n\n\nThe index for vertical layers is represented by \nzix\n.\n\n\n\n\n\n\nThe size of the domain in time, space, and vertical layers are\n    \nnTix\n, \nnPix\n, and \nnZix\n, respectively.\n\n\n\n\n\n\nNever use\n\n\n\n\n\n\n'tix' in an approach for anything else than the time index.\n\n\n\n\n\n\nthe SINDBAD variables \nf, fe, fx, s, d, p, info, tix, pix, zix\n\n    inside m files for approaches for anything else than the\n    intended meaning.\n\n\n\n\n\n\nvariable names that are used by matlab or other system command.\n    From MATLAB command line, check if the variable name (VarName)\n    is already defined by using\n\n\n\n\nexist \nVarName\n\n\n\n\n\n\n\n\nAvoid using\n\n\n\n\n\n\nsingle letters as variables as far as possible for clarity.\n\n\n\n\n\n\nsuffix of number to quickly name several variables. To keep the\n    code clean and readable, use reasonable and understandable\n    variable names.\n\n\n\n\n\n\nCurrently, we have not followed the conventions on variable naming. For\nreference, a list of variables following ALMA, CMIP, and CF conventions\nare put together at\n[https://git.bgc-jena.mpg.de/sindbad/sindbad/wikis/variablelist]{https://git.bgc-jena.mpg.de/sindbad/sindbad/wikis/variablelist}.\n\n\nModules\n\n\n\n\n\n\nEach module has a separate directory.\n\n\n\n\nThe directories are named in a logical way to provide key\n    information on the overarching process and the main function of\n    the module.\n\n\n\n\n\n\n\n\nFor calculating the effect of one variable on the other, the modules\n    are named in three parts:\n\n\n\n\n\n\nThe first part indicates the overarching process or a\n    biogeochemical variable, e.g. \nGPP\n\n\n\n\n\n\nThe second, optional part is additional information that relates\n    the first and third part, e.g.\n\n\n\n\n\n\nf\n: first part is the function of third part\n\n\n\n\n\n\n2\n: direction of a flow (e.g., wSoil2wGW for a transfer\n    from soil moisture storage to groundwater pool).\n\n\n\n\n\n\n\n\n\n\nThe third part is the main driver such as temperature, or an\n    object like soil evaporation component of evapotranspiration.\n\n\n\n\n\n\nFor example:\n\n\n\n\n\n\nGPPfTair\n - GPP as function of air temperature)\n\n\n\n\n\n\nwG2wSoil\n -- Groundwater flow to soil (capillary rise)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHydrological fluxes are often starting with \nQ\n, e.g., \nQsnw\n for\n    snowmelt, \nQsat\n for saturation excess runoff.\n\n\n\n\n\n\nAll evapotranspiration components, except transpiration, start with\n    \nEvap\n and end with the component, e.g., \nEvapSoil\n.\n\n\n\n\n\n\nAct\n is used at the end of variable name to represent the actual\n    amount. For example, \nGPPAct\n includes the effect of temperature,\n    soil moisture etc. on the potential GPP.\n\n\n\n\n\n\nCarbon cycle modules start with the letter 'c'.\n\n\n\n\n\n\nA short summary of the modules currently available in SINDBAD is in\n    the following table.\n\n\n\n\n\n\nTable 2. A list of SINDBAD Modules\n\n\n\n\n\n\n\n\nSN\n\n\nModule Name\n\n\nModule description\n\n\nRemarks\n\n\n\n\n\n\n\n\n\n\n1\n\n\ncAlloc\n\n\nCarbon Allocation\n\n\n\n\n\n\n\n\n2\n\n\ncAllocfLAI\n\n\nCarbon Allocation as a function of LAI\n\n\n\n\n\n\n\n\n3\n\n\ncAllocfNut\n\n\nCarbon Allocation as a function of nutrients\n\n\n\n\n\n\n\n\n4\n\n\ncAllocfTreeCover\n\n\nCarbon Allocation as a function of tree cover\n\n\n\n\n\n\n\n\n5\n\n\ncAllocfTsoil\n\n\nCarbon Allocation as a function of soil temperature\n\n\n\n\n\n\n\n\n6\n\n\ncAllocfwSoil\n\n\nCarbon Allocation as a function of soil moisture\n\n\n\n\n\n\n\n\n7\n\n\ncCycle\n\n\nCarbon cycle\n\n\nCalculates the transfers of carbon and gets the current carbon storages\n\n\n\n\n\n\n8\n\n\ncCycleBase\n\n\nThe base carbon cycle\n\n\nSets up the parameters for carbon transfers (called before calculating transfer, allocation, and turnover)\n\n\n\n\n\n\n9\n\n\ncFlowAct\n\n\nActual carbon transfer among carbon pools\n\n\n\n\n\n\n\n\n10\n\n\ncFlowfpSoil\n\n\nCarbon transfer as a function of soil parameters\n\n\n\n\n\n\n\n\n11\n\n\ncFlowfpVeg\n\n\nCarbon transfer as a function of vegetation parameters\n\n\n\n\n\n\n\n\n12\n\n\ncTauAct\n\n\nActual carbon turnover rate\n\n\n\n\n\n\n\n\n13\n\n\ncTaufLAI\n\n\nCarbon turnover rate as a function of LAI\n\n\n\n\n\n\n\n\n14\n\n\ncTaufpSoil\n\n\nCarbon turnover rate as a function of soil parameters\n\n\n\n\n\n\n\n\n15\n\n\ncTaufpVeg\n\n\nCarbon turnover rate as a function of vegetation parameters\n\n\n\n\n\n\n\n\n16\n\n\ncTaufTsoil\n\n\nCarbon turnover rate as a function of soil temperature\n\n\n\n\n\n\n\n\n17\n\n\ncTaufwSoil\n\n\nCarbon turnover rate as a function of soil moisture\n\n\n\n\n\n\n\n\n18\n\n\nEvapInt\n\n\nInterception Evaporation/loss\n\n\n\n\n\n\n\n\n19\n\n\nEvapSoil\n\n\nSoil evaporation\n\n\n\n\n\n\n\n\n20\n\n\nEvapSub\n\n\nSublimation\n\n\n\n\n\n\n\n\n21\n\n\ngetStates\n\n\nget the state of storages at the beginning of the time step\n\n\ncalled at the beginning of a time step before any module\n\n\n\n\n\n\n22\n\n\nGPPact\n\n\nActual GPP\n\n\n\n\n\n\n\n\n23\n\n\nGPPdem\n\n\nDemand limited GPP\n\n\n\n\n\n\n\n\n24\n\n\nGPPfRdiff\n\n\nGPP as a function of diffused radiation\n\n\n\n\n\n\n\n\n25\n\n\nGPPfRdir\n\n\nGPP as a function of direct radiation\n\n\n\n\n\n\n\n\n26\n\n\nGPPfTair\n\n\nGPP as a function of air temperature\n\n\n\n\n\n\n\n\n27\n\n\nGPPfVPD\n\n\nGPP as a function of vapor pressure deficit\n\n\n\n\n\n\n\n\n28\n\n\nGPPfwSoil\n\n\nGPP as a function of soil moisture\n\n\n\n\n\n\n\n\n29\n\n\nGPPpot\n\n\nPotential GPP\n\n\n\n\n\n\n\n\n30\n\n\npSoil\n\n\nsoil parameterization\n\n\n\n\n\n\n\n\n31\n\n\npTopo\n\n\ntopographical parameters\n\n\n\n\n\n\n\n\n32\n\n\npVeg\n\n\nvegetation parameters\n\n\n\n\n\n\n\n\n33\n\n\nQbase\n\n\nBase runoff/Baseflow\n\n\n\n\n\n\n\n\n34\n\n\nQinfExc\n\n\nInfiltration excess runoff\n\n\n\n\n\n\n\n\n35\n\n\nQint\n\n\nInterflow runoff\n\n\n\n\n\n\n\n\n36\n\n\nQsat\n\n\nSaturated excess runoff\n\n\n\n\n\n\n\n\n37\n\n\nQsnw\n\n\nSnowmelt\n\n\n\n\n\n\n\n\n38\n\n\nQwGRchg\n\n\nRecharge to groundwater reservoir\n\n\n\n\n\n\n\n\n39\n\n\nQwSoilRchg\n\n\nRecharge to soil/buffer reservoir\n\n\n\n\n\n\n\n\n40\n\n\nRAact\n\n\nActual autotrophic respiration\n\n\n\n\n\n\n\n\n41\n\n\nRAfTair\n\n\nAutotrophic respiration as a function of air temperature\n\n\n\n\n\n\n\n\n42\n\n\nstoreStates\n\n\nstore the states of the current time step (s.prev.) to be used in the next time step\n\n\ncalled at the end of a time step\n\n\n\n\n\n\n43\n\n\nTranAct\n\n\nActual transpiration\n\n\n\n\n\n\n\n\n44\n\n\nTranfwSoil\n\n\nTranspiration as a function of soil moisture\n\n\n\n\n\n\n\n\n45\n\n\nwG2wSoil\n\n\nwater available from groundwater to flow to soil moisture reservoir (capillary flux)\n\n\n\n\n\n\n\n\n46\n\n\nwRootUptake\n\n\nroot water uptake\n\n\n\n\n\n\n\n\n47\n\n\nwSnwFr\n\n\nSnow cover fraction of a grid cell\n\n\n\n\n\n\n\n\n48\n\n\nwSoilSatFr\n\n\nSaturated fraction of a grid cell\n\n\n\n\n\n\n\n\n49\n\n\nWUE\n\n\nwater use efficiency\n\n\n\n\n\n\n\n\n\n\nApproaches\n\n\n\n\n\n\nEach approach for a given module should have its own sub-directory.\n\n\n\n\n\n\nThe calculations for an approach can either be written in one matlab\n    function ('full'), or they can be split into two parts in order to\n    improve computational efficiency:\n\n\n\n\n\n\nparts that can be precomputed ('prec')\n\n\n\n\n\n\nparts that are state dependent ('dyna')\n\n\n\n\n\n\n\n\n\n\nThus, there should be the following files within the approach's\n    sub-directory:\n\n\n\n\n\n\nThe '\nfull\n' file for the approach\n\n\n\n\n\n\nincludes the full code of the approach with precomputations\n    and dynamic calculations.\n\n\n\n\n\n\nAn implementation of a new approach should always be done\n    with the full file.\n\n\n\n\n\n\nThe full file is named as:\n\n\n\n\n\n\n[ModuleName]_[ApproachName].m\n, e.g.,\n    \ncAlloc_Fix.m\n\n\n\n\n\n\nThis function is called from within the time loop. So,\n    it includes \ntix\n in the input arguments.\n\n\n\n\nfunction [f,fe,fx,s,d,p] =\n    cAlloc_Fix(f,fe,fx,s,d,p,info, tix)\n\n\n\n\n\n\n\n\n\n\n\n\nSINDBAD can be forced to use the full version by setting the\n    \nrunFull\n option in the \nmodelStructure[.json]\n\n    configuration file to \nTrue\n .\n\n\n\n\n\n\n\n\n\n\nInstead of/in addition to the full approach file, it is possible\n    to split the full code into two .m files with precomputations\n    and dynamic calculations separated as:\n\n\n\n\n\n\n'\nprec\n'\n\n\n\n\n\n\na .m file with the code and calculations that are\n    \nindependent of states\n and can be \nprec\nomputed\n    outside the time loop.\n\n\n\n\n\n\nprec_[ModuleName]_[ApproachName].m,\n e.g.,\n    *prec_cAlloc_Fix.m *\n\n\n\n\n\n\nThis function is independent of state and is not\n    called from within the time loop. So, it does not\n    include \ntix\n in the inform within the time loop.\n    So, it does not include \ntix\n in the input\n    arguments.\n\n\n\n\nfunction [f,fe,fx,s,d,p] =\n    prec_cAlloc_Fix(f,fe,fx,s,d,p,info)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n'\ndyna\n'\n\n\n\n\n\n\na .m file with the code and calculations that are\n    \ndependent on states (time)\n and should be computed\n    within the time loop. These time-dependent calculations\n    are referred as \ndyna\nmic in time, and named as:\n\n\n\n\n\n\ndyna_[ModuleName]_[ApproachName].m\n, e.g.,\n    \ndyna_cAlloc_Fix.m\n\n\n\n\n\n\nSimilar to the 'full' function, this function is\n    called from within the time loop. So, it includes\n    \ntix\n in the input arguments.\n\n\n\n\nfunction [f,fe,fx,s,d,p] =\n    dyna_cAlloc_Fix(f,fe,fx,s,d,p,info, tix)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn case the \nprec\n and \ndyna\n files are not\n    provided, the \nrunFull\n option must be set to True\n in\n    the \nmodelStructure[.json]\n configuration file.\n\n\n\n\n\n\n\n\n\n\nIf needed, a \nparameter file\n that includes information on the\n    parameters, their values, value ranges, etc.\n\n\n\n\n\n\nThe format should be \n.json\n.\n\n\n\n\n\n\nThe file is named as \n[ModuleName]_[ApproachName].json\n\n\n\n\n\n\nIf no parameter files are provided, the parameters of the\n    model cannot be changed, i.e. optimized, and need be\n    hard-coded in the approach file(s).\n\n\n\n\nSee\n    model/modules/Qint/Qint_Bergstroem/Qint_Bergstroem.json\n    for an example.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBesides, two special approaches exist for each module:\n\n\n\n\n\n\nA '\ndummy'\n approach: A dummy approach is an empty approach.\n\n\n\n\n\n\nIt does not have any calculation and does not calculate any\n    output variable.\n\n\n\n\nTherefore, effectively, choosing a dummy approach is the\n    same as switching off a module without changing the list\n    of modules executed in the core.\n\n\n\n\n\n\n\n\nThe dummy approach is the \ndefault for all modules\n. Only\n    the modules for which approaches other than dummy have been\n    set in the \nmodelStructure[.json]\n are turned 'on'.\n\n\n\n\n\n\nWhen a new module is implemented, a dummy approach should\n    always be created.\n\n\n\n\n\n\nDummy approaches do not need \nprec\n and \ndyna\n functions\n    and can only have the full function with no content.\n\n\n\n\n\n\n\n\n\n\nA '\nnone'\n approach: A none approach is used when the output\n    variable refers to 'no effect', for e.g., when a calculated\n    stress scalar is always set to 1.\n\n\n\n\nIt is not necessarily equivalent to the \"dummy\".\n\n\n\n\n\n\n\n\n\n\n\n\nThe \nname of an approach\n (full, prec, and dyna) should always\n    include the name of the module as,\n\n\n\n\n[ModuleName]_[ApproachName].m\n\n\n\n\n\n\n\n\nThe ApproachName part of the name should reflect the module,\n    actions, calculated variables, and/or include information on\n\n\n\n\n\n\nHow\n a variable is calculated \nusing what\n\n\n\n\ne.g., \nQsnw_nonlinRad.m\n for snowmelt based on non-linear\n    function of radiation. Note than Qsnw is the name of the\n    module.\n\n\n\n\n\n\n\n\nWhich method\n is being used to do the calculation\n\n\n\n\ne.g., \nTranAct_TEA.m\n for calculation of actual\n    transpiration based on the TEA algorithm.\n\n\n\n\n\n\n\n\nThe \nauthor's last name and year\n of publication if the\n    approach is based on a previous study,\n\n\n\n\n\n\nas [\nModuleName]_LastNameYYYY.m\n\n\n\n\n\n\ne.g. \nQbas_Zhang2008.m\n for calculation of saturated runoff\n    based on Zhang et al. (2008).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEach approach should have the same input and output arguments\n.\n\n\n\n\ne.g. \nfunction [f,fe,fx,s,d,p] =\n    [ModuleName]_[ApproachName](f,fe,fx,s,d,p,info, tix)\n\n\n\n\n\n\n\n\nEach approach function needs to have an 'end' or 'return' in the\n    last line.\n\n\n\n\n\n\nNever use: \n\n\n\n\n\n\n'_' within the [ApproachName].\n\n\n\n\n\n\nthe variables '\nf,fe,fx,s,d,p,info,tix\n' inside the approaches'\n    .m files\n\n\n\n\n\n\n\n\n\n\nFunctions\n\n\nThis convention of functions is only applicable to all functions except\nthe \nmodules and approaches\n, which shoud \nfollow their own\nconventions\n described beforehand.\n\n\n\n\n\n\nThe function naming should follow a clear and tangible pattern of\n    [Action][Object].\n\n\n\n\n\n\nThe name of the action should always start with a small letter\n    for typeability/writability.\n\n\n\n\n\n\nThe name of the object should always start with a capital letter\n    for readability.\n\n\n\n\n\n\n\n\n\n\nFor consistency, the actions and their purposes are defined clearly\n    in the following table.\n\n\n\n\nIf there are missing actions, then such actions should be\n    proposed to core developer before being implemented.\n\n\n\n\n\n\n\n\nThe objects may include:\n\n\n\n\n\n\nA metric such as the model cost based on a specific study. For\n    example, a function named calcCostTWSPaper calculates the model\n    cost as described in the TWS paper.\n\n\n\n\n\n\nconceptual model components such as model output or structure,\n    e.g., editINFOsettings.m\n\n\n\n\n\n\nthe function's purpose, i.e., the use of the output of the\n    function, e.g., \naggObs4Optimization.m\n.\n\n\n\n\n\n\n\n\n\n\nThe naming of the objects, especially for functions setting up the\n    'info' should reflect the naming conventions used in the\n    organization of the info.\n\n\n\n\n\n\nTable 3. Actions used in naming functions\n\n\n\n\n\n\n\n\nAction\n\n\nExplanation\n\n\nComment\n\n\nExample\n\n\n\n\n\n\n\n\n\n\nagg\n\n\nAggregate variable\n\n\n\n\naggOutput\n\n\n\n\n\n\ncalc\n\n\nCalculate or compute a variable\n\n\ne.g., usage in approaches\n\n\ncalcGPPfTair\n\n\n\n\n\n\ncheck\n\n\nCarry out a check\n\n\n\n\ncheckModelStructure, checkCarbonBalance, checkBounds, checkDataSanity\n\n\n\n\n\n\ncreate\n\n\nCreating objects such as arrays that can be copied in subsequent parts of the model\n\n\nspeeds up the model\n\n\n\n\n\n\n\n\ndyna\n\n\nexclusively used for naming the approaches to identify the dynamic time-dependent part of an approach\n\n\nto calculate variables that are dependent on states\n\n\ndyna_module_approach.m\n\n\n\n\n\n\nedit\n\n\nEdit the objects. Currently used in editing the fields of info\n\n\n\n\neditINFOsettings\n\n\n\n\n\n\ngen\n\n\nGenerate\n\n\n\n\ngenCode4Core\n\n\n\n\n\n\nget\n\n\nGet information from modules\n\n\n\n\ngetDates, getCore\n\n\n\n\n\n\ninit\n\n\nInitialize. Use only in the context of initializing storage states.\n\n\n\n\n\n\n\n\n\n\nkeep\n\n\nKeep something (don\u2019t overwrite). Use for states to access the storage from previous time step without overwriting\n\n\n\n\n\n\n\n\n\n\nprep\n\n\nPrepare an object\n\n\n\n\nprepForcing\n\n\n\n\n\n\nprec\n\n\nexclusively used for naming the approaches to identify the precomputation part\n\n\nto calculate variables that are independent of states and time\n\n\nprec_module_approach.m\n\n\n\n\n\n\nread\n\n\nRead information from files\n\n\n\n\nreadParamsConfig, readOutputConfig, readRestartfile\n\n\n\n\n\n\nrun\n\n\nRun model or spinup or optimizer\n\n\n\n\nrunModel\n\n\n\n\n\n\nset\n\n\nSet or modify contents of Info based on config files\n\n\n\n\nsetTime\n\n\n\n\n\n\nsetup\n\n\nSetting something up, often related to conceptual model components\n\n\n\n\nsetupModelStructure, setupExperiment\n\n\n\n\n\n\nstore\n\n\nStore the full time-series of a state/flux variable in memory\n\n\n\n\nstoreStates\n\n\n\n\n\n\nwrite\n\n\nWrite to file\n\n\n\n\nwriteStates\n\n\n\n\n\n\n\n\nDocumentation\n\n\n\n\n\n\nAll functions and modules should be documented at the beginning with\n    a fixed standard format. They should at least have the following\n    fields:\n\n\n\n\n\n\nUsages with Inputs and Outputs\n\n\n\n\n\n\nRequires\n\n\n\n\n\n\nPurposes\n\n\n\n\n\n\nConventions\n\n\n\n\n\n\nReferences\n\n\n\n\n\n\nVersions\n\n\n\n\n\n\n\n\n\n\nThe header of a function should contain at least the following:\n\n\n% Usages:\n%   [s,d,info] = createStatesArrays(s,d,info)\n%\n% Requires:\n%   + a list of variables:\n%       ++ state variables: info.tem.model.variables.states.input\n%   + information on whether or not to combine the pool:\n%       ++ info.tem.model.variables.states.input.(sv).combine\n% Purposes:\n%   + Creates the arrays for the state variables needed to run the model.\n\n% Conventions:\n%   + d.storedStates.[VarName]: nPix,nZix,nTix\n%\n% Created by:\n%   + Sujan Koirala (skoirala@bgc-jena.mpg.de)\n%\n% References:\n%   +\n%\n% Versions:\n%   + 1.0 on 17.04.2018\n\n\n\n\n\n\n\n\n\nAll mathematical equations should be written in the comments or near\n    where the equation is coded. This is necessary to track if there is\n    error in the intended formulation.\n\n\n\n\n\n\nDetailed comments should be inserted throughout the code when\n    complicated steps need to be taken.\n\n\n\n\n\n\nLater, the code comments will be converted to official documentation\n    using mtoc++ and doxygen (\nhttps://github.com/mdrohmann/mtocpp\n and\n    \nhttp://www.ians.uni-stuttgart.de/MoRePaS/software/mtocpp/docs/tools.html\n)", 
            "title": "Coding Conventions"
        }, 
        {
            "location": "/conventions/#general", 
            "text": "Always follow all the conventions in this document. In case there is\n    a question on clarification, ask an experienced developer.    Maintain associations between function names and field names of the\n    'info'. For example,    Optimization is abbreviated to opti in info. So, a function that\n    prepares the optimization should be prepOpti.m rather than\n    prepare_Optimization.m.    The model is referred to as tem. The functions that runs the\n    model is named runTEM.m rather than runModel.m.      Consider the perspective of \"someone else\" who needs to \"modify how\"\n    things are done with respect to \"something\"; i.e., tangibility of\n    the variables, function names, and so on.    For example,    a function calculates the outflow for a pool based on\n    different mathematical formulations. If the output flux is\n    say baseflow (Qbase) from groundwater (wGW) storage. For a\n    linear function, use the name Qbase_linwGW.m    A variable should be named in a way that explains what is\n    being done. For GPP as a function of Tair should be GPPfTair\n    = ....      for making the code intuitive and maintaining the integrity of\n    the model.      Always report inconsistencies, bugs, and error in the code to the\n    development team.   This should always be done by creating an issue in gitLab.", 
            "title": "General"
        }, 
        {
            "location": "/conventions/#variables", 
            "text": "The state variables of an element are identified with the\n    starting letter of the element at the beginning of a variable\n    name. 'c' and 'w' are used for carbon and water state variables,\n    respectively.   For example, soil moisture storage is name  wSoil .\n    Vegetation carbon pool is represented as  cVeg .     All the water storages are represented by  wPools .    All the carbon pools are represented by a single variable\n     cEco , which may contain  cVeg ,  cRoot , and so on.    Note that cEco is not the total carbon storage. It is a\n    variable that has all the component pools in one array. For\n    example, if there are 14 pools (nZix) and 1000 pixels\n    (nPix), the size of cEco for 1 time step is 1000,14,1.    This variable is only generated when combinePools option is\n    set to true in modelStructure[.json] configuration file.      The time index is represented by  tix .    The space index is represented by  pix .    The index for vertical layers is represented by  zix .    The size of the domain in time, space, and vertical layers are\n     nTix ,  nPix , and  nZix , respectively.    Never use    'tix' in an approach for anything else than the time index.    the SINDBAD variables  f, fe, fx, s, d, p, info, tix, pix, zix \n    inside m files for approaches for anything else than the\n    intended meaning.    variable names that are used by matlab or other system command.\n    From MATLAB command line, check if the variable name (VarName)\n    is already defined by using   exist  VarName     Avoid using    single letters as variables as far as possible for clarity.    suffix of number to quickly name several variables. To keep the\n    code clean and readable, use reasonable and understandable\n    variable names.    Currently, we have not followed the conventions on variable naming. For\nreference, a list of variables following ALMA, CMIP, and CF conventions\nare put together at\n[https://git.bgc-jena.mpg.de/sindbad/sindbad/wikis/variablelist]{https://git.bgc-jena.mpg.de/sindbad/sindbad/wikis/variablelist}.", 
            "title": "Variables"
        }, 
        {
            "location": "/conventions/#modules", 
            "text": "Each module has a separate directory.   The directories are named in a logical way to provide key\n    information on the overarching process and the main function of\n    the module.     For calculating the effect of one variable on the other, the modules\n    are named in three parts:    The first part indicates the overarching process or a\n    biogeochemical variable, e.g.  GPP    The second, optional part is additional information that relates\n    the first and third part, e.g.    f : first part is the function of third part    2 : direction of a flow (e.g., wSoil2wGW for a transfer\n    from soil moisture storage to groundwater pool).      The third part is the main driver such as temperature, or an\n    object like soil evaporation component of evapotranspiration.    For example:    GPPfTair  - GPP as function of air temperature)    wG2wSoil  -- Groundwater flow to soil (capillary rise)        Hydrological fluxes are often starting with  Q , e.g.,  Qsnw  for\n    snowmelt,  Qsat  for saturation excess runoff.    All evapotranspiration components, except transpiration, start with\n     Evap  and end with the component, e.g.,  EvapSoil .    Act  is used at the end of variable name to represent the actual\n    amount. For example,  GPPAct  includes the effect of temperature,\n    soil moisture etc. on the potential GPP.    Carbon cycle modules start with the letter 'c'.    A short summary of the modules currently available in SINDBAD is in\n    the following table.    Table 2. A list of SINDBAD Modules     SN  Module Name  Module description  Remarks      1  cAlloc  Carbon Allocation     2  cAllocfLAI  Carbon Allocation as a function of LAI     3  cAllocfNut  Carbon Allocation as a function of nutrients     4  cAllocfTreeCover  Carbon Allocation as a function of tree cover     5  cAllocfTsoil  Carbon Allocation as a function of soil temperature     6  cAllocfwSoil  Carbon Allocation as a function of soil moisture     7  cCycle  Carbon cycle  Calculates the transfers of carbon and gets the current carbon storages    8  cCycleBase  The base carbon cycle  Sets up the parameters for carbon transfers (called before calculating transfer, allocation, and turnover)    9  cFlowAct  Actual carbon transfer among carbon pools     10  cFlowfpSoil  Carbon transfer as a function of soil parameters     11  cFlowfpVeg  Carbon transfer as a function of vegetation parameters     12  cTauAct  Actual carbon turnover rate     13  cTaufLAI  Carbon turnover rate as a function of LAI     14  cTaufpSoil  Carbon turnover rate as a function of soil parameters     15  cTaufpVeg  Carbon turnover rate as a function of vegetation parameters     16  cTaufTsoil  Carbon turnover rate as a function of soil temperature     17  cTaufwSoil  Carbon turnover rate as a function of soil moisture     18  EvapInt  Interception Evaporation/loss     19  EvapSoil  Soil evaporation     20  EvapSub  Sublimation     21  getStates  get the state of storages at the beginning of the time step  called at the beginning of a time step before any module    22  GPPact  Actual GPP     23  GPPdem  Demand limited GPP     24  GPPfRdiff  GPP as a function of diffused radiation     25  GPPfRdir  GPP as a function of direct radiation     26  GPPfTair  GPP as a function of air temperature     27  GPPfVPD  GPP as a function of vapor pressure deficit     28  GPPfwSoil  GPP as a function of soil moisture     29  GPPpot  Potential GPP     30  pSoil  soil parameterization     31  pTopo  topographical parameters     32  pVeg  vegetation parameters     33  Qbase  Base runoff/Baseflow     34  QinfExc  Infiltration excess runoff     35  Qint  Interflow runoff     36  Qsat  Saturated excess runoff     37  Qsnw  Snowmelt     38  QwGRchg  Recharge to groundwater reservoir     39  QwSoilRchg  Recharge to soil/buffer reservoir     40  RAact  Actual autotrophic respiration     41  RAfTair  Autotrophic respiration as a function of air temperature     42  storeStates  store the states of the current time step (s.prev.) to be used in the next time step  called at the end of a time step    43  TranAct  Actual transpiration     44  TranfwSoil  Transpiration as a function of soil moisture     45  wG2wSoil  water available from groundwater to flow to soil moisture reservoir (capillary flux)     46  wRootUptake  root water uptake     47  wSnwFr  Snow cover fraction of a grid cell     48  wSoilSatFr  Saturated fraction of a grid cell     49  WUE  water use efficiency", 
            "title": "Modules"
        }, 
        {
            "location": "/conventions/#approaches", 
            "text": "Each approach for a given module should have its own sub-directory.    The calculations for an approach can either be written in one matlab\n    function ('full'), or they can be split into two parts in order to\n    improve computational efficiency:    parts that can be precomputed ('prec')    parts that are state dependent ('dyna')      Thus, there should be the following files within the approach's\n    sub-directory:    The ' full ' file for the approach    includes the full code of the approach with precomputations\n    and dynamic calculations.    An implementation of a new approach should always be done\n    with the full file.    The full file is named as:    [ModuleName]_[ApproachName].m , e.g.,\n     cAlloc_Fix.m    This function is called from within the time loop. So,\n    it includes  tix  in the input arguments.   function [f,fe,fx,s,d,p] =\n    cAlloc_Fix(f,fe,fx,s,d,p,info, tix)       SINDBAD can be forced to use the full version by setting the\n     runFull  option in the  modelStructure[.json] \n    configuration file to  True  .      Instead of/in addition to the full approach file, it is possible\n    to split the full code into two .m files with precomputations\n    and dynamic calculations separated as:    ' prec '    a .m file with the code and calculations that are\n     independent of states  and can be  prec omputed\n    outside the time loop.    prec_[ModuleName]_[ApproachName].m,  e.g.,\n    *prec_cAlloc_Fix.m *    This function is independent of state and is not\n    called from within the time loop. So, it does not\n    include  tix  in the inform within the time loop.\n    So, it does not include  tix  in the input\n    arguments.   function [f,fe,fx,s,d,p] =\n    prec_cAlloc_Fix(f,fe,fx,s,d,p,info)         ' dyna '    a .m file with the code and calculations that are\n     dependent on states (time)  and should be computed\n    within the time loop. These time-dependent calculations\n    are referred as  dyna mic in time, and named as:    dyna_[ModuleName]_[ApproachName].m , e.g.,\n     dyna_cAlloc_Fix.m    Similar to the 'full' function, this function is\n    called from within the time loop. So, it includes\n     tix  in the input arguments.   function [f,fe,fx,s,d,p] =\n    dyna_cAlloc_Fix(f,fe,fx,s,d,p,info, tix)         In case the  prec  and  dyna  files are not\n    provided, the  runFull  option must be set to True  in\n    the  modelStructure[.json]  configuration file.      If needed, a  parameter file  that includes information on the\n    parameters, their values, value ranges, etc.    The format should be  .json .    The file is named as  [ModuleName]_[ApproachName].json    If no parameter files are provided, the parameters of the\n    model cannot be changed, i.e. optimized, and need be\n    hard-coded in the approach file(s).   See\n    model/modules/Qint/Qint_Bergstroem/Qint_Bergstroem.json\n    for an example.         Besides, two special approaches exist for each module:    A ' dummy'  approach: A dummy approach is an empty approach.    It does not have any calculation and does not calculate any\n    output variable.   Therefore, effectively, choosing a dummy approach is the\n    same as switching off a module without changing the list\n    of modules executed in the core.     The dummy approach is the  default for all modules . Only\n    the modules for which approaches other than dummy have been\n    set in the  modelStructure[.json]  are turned 'on'.    When a new module is implemented, a dummy approach should\n    always be created.    Dummy approaches do not need  prec  and  dyna  functions\n    and can only have the full function with no content.      A ' none'  approach: A none approach is used when the output\n    variable refers to 'no effect', for e.g., when a calculated\n    stress scalar is always set to 1.   It is not necessarily equivalent to the \"dummy\".       The  name of an approach  (full, prec, and dyna) should always\n    include the name of the module as,   [ModuleName]_[ApproachName].m     The ApproachName part of the name should reflect the module,\n    actions, calculated variables, and/or include information on    How  a variable is calculated  using what   e.g.,  Qsnw_nonlinRad.m  for snowmelt based on non-linear\n    function of radiation. Note than Qsnw is the name of the\n    module.     Which method  is being used to do the calculation   e.g.,  TranAct_TEA.m  for calculation of actual\n    transpiration based on the TEA algorithm.     The  author's last name and year  of publication if the\n    approach is based on a previous study,    as [ ModuleName]_LastNameYYYY.m    e.g.  Qbas_Zhang2008.m  for calculation of saturated runoff\n    based on Zhang et al. (2008).        Each approach should have the same input and output arguments .   e.g.  function [f,fe,fx,s,d,p] =\n    [ModuleName]_[ApproachName](f,fe,fx,s,d,p,info, tix)     Each approach function needs to have an 'end' or 'return' in the\n    last line.    Never use:     '_' within the [ApproachName].    the variables ' f,fe,fx,s,d,p,info,tix ' inside the approaches'\n    .m files", 
            "title": "Approaches"
        }, 
        {
            "location": "/conventions/#functions", 
            "text": "This convention of functions is only applicable to all functions except\nthe  modules and approaches , which shoud  follow their own\nconventions  described beforehand.    The function naming should follow a clear and tangible pattern of\n    [Action][Object].    The name of the action should always start with a small letter\n    for typeability/writability.    The name of the object should always start with a capital letter\n    for readability.      For consistency, the actions and their purposes are defined clearly\n    in the following table.   If there are missing actions, then such actions should be\n    proposed to core developer before being implemented.     The objects may include:    A metric such as the model cost based on a specific study. For\n    example, a function named calcCostTWSPaper calculates the model\n    cost as described in the TWS paper.    conceptual model components such as model output or structure,\n    e.g., editINFOsettings.m    the function's purpose, i.e., the use of the output of the\n    function, e.g.,  aggObs4Optimization.m .      The naming of the objects, especially for functions setting up the\n    'info' should reflect the naming conventions used in the\n    organization of the info.    Table 3. Actions used in naming functions     Action  Explanation  Comment  Example      agg  Aggregate variable   aggOutput    calc  Calculate or compute a variable  e.g., usage in approaches  calcGPPfTair    check  Carry out a check   checkModelStructure, checkCarbonBalance, checkBounds, checkDataSanity    create  Creating objects such as arrays that can be copied in subsequent parts of the model  speeds up the model     dyna  exclusively used for naming the approaches to identify the dynamic time-dependent part of an approach  to calculate variables that are dependent on states  dyna_module_approach.m    edit  Edit the objects. Currently used in editing the fields of info   editINFOsettings    gen  Generate   genCode4Core    get  Get information from modules   getDates, getCore    init  Initialize. Use only in the context of initializing storage states.      keep  Keep something (don\u2019t overwrite). Use for states to access the storage from previous time step without overwriting      prep  Prepare an object   prepForcing    prec  exclusively used for naming the approaches to identify the precomputation part  to calculate variables that are independent of states and time  prec_module_approach.m    read  Read information from files   readParamsConfig, readOutputConfig, readRestartfile    run  Run model or spinup or optimizer   runModel    set  Set or modify contents of Info based on config files   setTime    setup  Setting something up, often related to conceptual model components   setupModelStructure, setupExperiment    store  Store the full time-series of a state/flux variable in memory   storeStates    write  Write to file   writeStates", 
            "title": "Functions"
        }, 
        {
            "location": "/conventions/#documentation", 
            "text": "All functions and modules should be documented at the beginning with\n    a fixed standard format. They should at least have the following\n    fields:    Usages with Inputs and Outputs    Requires    Purposes    Conventions    References    Versions      The header of a function should contain at least the following:  % Usages:\n%   [s,d,info] = createStatesArrays(s,d,info)\n%\n% Requires:\n%   + a list of variables:\n%       ++ state variables: info.tem.model.variables.states.input\n%   + information on whether or not to combine the pool:\n%       ++ info.tem.model.variables.states.input.(sv).combine\n% Purposes:\n%   + Creates the arrays for the state variables needed to run the model.\n\n% Conventions:\n%   + d.storedStates.[VarName]: nPix,nZix,nTix\n%\n% Created by:\n%   + Sujan Koirala (skoirala@bgc-jena.mpg.de)\n%\n% References:\n%   +\n%\n% Versions:\n%   + 1.0 on 17.04.2018    All mathematical equations should be written in the comments or near\n    where the equation is coded. This is necessary to track if there is\n    error in the intended formulation.    Detailed comments should be inserted throughout the code when\n    complicated steps need to be taken.    Later, the code comments will be converted to official documentation\n    using mtoc++ and doxygen ( https://github.com/mdrohmann/mtocpp  and\n     http://www.ians.uni-stuttgart.de/MoRePaS/software/mtocpp/docs/tools.html )", 
            "title": "Documentation"
        }, 
        {
            "location": "/configuration/", 
            "text": "The SINDBAD model structure and simulations are defined by a set of\n\nconfiguration files written in the .json format\n. All the configuration\nfiles for a given experiment should be saved inside a separate directory\nwithin the \nsettings\n directory of the SINDBAD root. An example of a\nset of configuration files is in settings/cCycle_debug directory of\nroot SINDBAD directory.\n\n\nWhile developing, it is recommended to change the names of the\nconfiguration files, so that the they can be easily associated with the\nrespective experiment, and to keep the experiment setup traceable and\nreproduceable. For example, the file names below can be extended with\nadditional information, e.g. \nspinup.json\n can be changed to\n\nspinup_cCycle_2000years.json\n.\n\n\nIn the following, the configuration files of SINDBAD are described briefly.\n\n\nexperiment\n\n\nThe central configuration file for a simulation is the \nexperiment\n    file\n \n[experiment*.json]\n, which lists the paths to the individual configuration files.\n\n\n{\n    \nname\n: \nFluxnetSiteOptimization\n,\n    \ndomain\n: \nFR-Hes\n,\n    \nconfigFiles\n: {\n        \nforcing\n       : \nsettings/runOpti/forcing.json\n,\n        \nmodelStructure\n: \nsettings/runOpti/modelStructure_cCycle_CASA.json\n,\n        \nconstants\n     : \nsettings/runOpti/constants.json\n,\n        \nmodelRun\n      : \nsettings/runOpti/modelRun.json\n,\n        \noutput\n        : \nsettings/runOpti/output.json\n,\n        \nspinup\n        : \nsettings/runOpti/spinup.json\n,\n        \nparams\n        : \nsettings/runOpti/params.json\n,\n        \nopti\n          : \nsettings/runOpti/opti.json\n\n    },\n    \noutputInfoFile\n: \nsandbox/sb_runOpti/FR-Hes/FluxnetSiteOptimizationInfo4FR-Hes.json\n,\n    \noutputDirPath\n : \nsandbox/sb_runOpti/FR-Hes/\n\n}\n\n\n\n\nforcing\n\n\ncontains the information related to each forcing\n    variable as well as the name of the function to read the forcing\n    data files and put the data in SINDBAD structure \nf\n.\n\n\n{\n    \nfunName\n: {\n        \nimport\n: \nreadExpStruct\n,\n        \ncheck\n: \ncheckInputData\n\n    },\n    \nComments\n: \nto get forcing from ExpStruct of TWS model\n,\n    \nsize\n: [Inf, Inf],\n    \nVariableNames\n: [\nLAI\n,\nRn\n, \nRain\n, \nSnow\n, \nTair\n, \nTairDay\n, \nPsurfDay\n,\nPET\n],\n    \nLAI\n: {\n        \nVariableUnit\n: \nm2 m-2\n,\n        \nSourceVariableName\n: \nLAI\n,\n        \nSourceVariableUnit\n: \nm2 m-2\n,\n        \nSource2sindbadUnit\n: \n*1\n,\n        \nisCategorical\n: false,\n        \nNameShort\n: \nLAI\n,\n        \nSpaceTimeType\n: \nnormal\n,\n        \nSourceDataProductName\n: \ndummy\n,\n        \nDataPath\n: \ninput/testInput_TWSmodel/ExpStruct_1000pix_10years_test.mat\n\n    },\n}\n\n\n\n\nmodelStructure\n\n\ncontains the information related to the selected\n    approaches for the modules, as well as the information related to\n    carbon and water state variables. It also contains the paths for\n\n\n\n\n\n\nthe modules directory\n\n\n\n\n\n\nthe core (default is \ncoreTEM.m\n)\n\n\n\n\n\n\n{\n    \npaths\n: \n    {\n        \ncoreTEM\n:          \nmodel/core/coreTEM.m\n,\n        \nmodulesDir\n:       \nmodel/modules/\n\n    },\n\n    \nmodules\n: \n    {\n        \ngetStates\n: \n        {\n            \napprName\n:     \ngetStates_simple\n,\n            \nrunFull\n:      true,\n            \nuse4spinup\n:   false\n        },\n        \ncFlowAct\n:\n        {\n            \napprName\n:     \ncFlowAct_simple\n,\n            \nrunFull\n:      true,\n            \nuse4spinup\n:   false\n        },\n    },  \n    \nstates\n: \n    {\n        \nw\n: \n        {\n            \npools\n : \n            [\n                [\nw.Surf\n,      1,  \nzeros\n],\n                [\nw.Soil\n,      1,  \nzeros\n],\n                ...\n            ],\n            \ncombine\n:      [false,\nwPools\n,\nzeros\n]\n        },\n        \nwd\n: \n        {\n            \npools\n : \n            [\n                [\nWTD\n,         1,  \nzeros\n],\n                [\nw.SnowFrac\n,  1,  \nzeros\n]\n            ],\n            \ncombine\n:      [false,\nwStates\n,\nzeros\n]\n        },\n        \nc\n: \n        {\n        \npools\n : \n        [\n            [\nc.Veg.Root.F\n,    1,  \nzeros\n],\n            [\nc.Veg.Root.C\n,    1,  \nzeros\n],\n            [\nc.Veg.Wood\n,      1,  \nzeros\n],\n            ...\n        ],\n        }\n    }\n}\n\n\n\n\n\nconstants\n\n\ncontains a list of physical constants that can be\n    accessed in any function within SINDBAD.\n\n\n{\n    \nconstants\n:\n    {\n        \nG\n: [0]\n    }\n}\n\n\n\n\nmodelRun\n\n\ncontains configuration for setting up the model,\n    generating the code, and running the model:\n\n\n\n\n\n\nInformation related to the time period of the model run.\n\n\n\n\n\n\nThe temporary directory for a SINDBAD simulation (\nrunDir\n).\n\n\n\n\n\n\nThe paths of the generated core and \nprecOnce\n.\n\n\n\n\n\n\nIf and what checks for carbon and water balance should be done.\n\n\n\n\n\n\nThe precision of the array (computation) to be used during the\n    SINDBAD simulation.\n\n\n\n\n\n\n{\n    \ntime\n: \n    {\n        \nstep\n:                 \nd\n,\n        \nsDate\n:                \n2002-01-01\n,\n        \neDate\n:                \n2011-12-31\n,\n        \nnYears\n:               [10],\n        \nnStepsDay\n:            [1],\n        \nnStepsYear\n:           [365]\n    },\n    \npaths\n: {\n        \nrunDir\n:               \noutput/CASA/\n,\n        \ngenCode\n: \n        {\n            \ncoreTEM\n:          \n,\n            \npreCompOnce\n:      \n\n        }\n    },\n    \nflags\n: \n    {\n        \nforwardRun\n:           true,\n        \nrunGenCode\n:           true,\n        \ngenCode\n:              true,\n        \ngenRedMemCode\n:        false,\n        \nrunOpti\n:              false,\n        \nchecks\n: \n        {\n            \nmassBalance\n: \n            {\n                \ncarbon\n:       false,\n                \nwater\n:        false\n            },\n            \nnumeric\n:          false,\n            \nbounds\n:           false\n        }\n    },\n    \nrules\n: \n    {\n        \narrayPrecision\n:       \nsingle\n\n    }\n}\n\n\n\n\noutput\n\n\ncontains the information on the model output, and the\n    list of variables that should be stored during the model simulation.\n\n\n{\n    \nvariables\n: {\n        \nto\n: {\n            \nwrite\n: [\ns.w.wGW\n, \ns.w.wSnow\n, \ns.w.wSoil\n,\ns.c.cEco\n]\n        }\n    }\n}\n\n\n\n\nspinup\n\n\ncontains the information on how to carry out the spinup,\n    such as number of model years to run, or if the spinup should be\n    loaded from a file, etc.\n\n\n{\n    \nsequence\n: \n    [\n        {\n            \nfunHandleSpin\n:        \nrunCoreTEM\n,\n            \nfunHandleStop\n:        \n,\n            \nfunAddInputs\n:         [false,false,true],\n            \nnLoops\n:               10\n        },\n        {\n            \nfunHandleSpin\n:        \nrunCoreTEM\n,\n            \nfunHandleStop\n:        \n,\n            \nfunAddInputs\n:         [true,true,false],\n            \nnLoops\n: 1\n        }\n    ],\n    \npaths\n: \n    {\n        \nrestartFile\n:              \nsettings/restartFile.xxx\n\n    },\n    \nflags\n: \n    {\n        \nrecycleMSC\n:               true,\n        \nrunSpinup\n:                true,\n        \nloadSpinup\n:               false\n    }\n}\n\n\n\n\nopti\n\n\ncontains information on the optimization, such as the\n    optimization scheme, the parameters to be optimized, a list of\n    observational constraints and a function to read them, etc.\n\n\n{\n    \ncostFun\n: {\n        \ncostName\n: \ncalcCostTWSPaper\n,\n        \ncostFunsFile\n: \noptimization/costFunctions/optionsCostFunctions.json\n\n    },\n    \nmethod\n: {\n        \nfunName\n: \ncmaes\n,\n        \ndefaultOptimOptions\n: \noptimization/optimSchemes/optionsOptimizationSchemes.json\n\n    },\n    \nparams2opti\n: [\nwSnwFr.CoverParam\n, ....],\n    \nchecks\n: \n,\n    \nconstraints\n: {\n        \nfunName\n: {\n            \nimport\n: \nreadExpStructConstraints\n,\n            \ncheck\n: \n\n        },\n        \nComments\n: \nto get calibration data from ExpStruct of TWS model\n,\n        \nVariableNames\n: [\nTWSobs\n, \nSWEobs\n, \nEvapobs\n, \nQrobs\n],\n        \nTWSobs\n: {\n            \nVariableUnit\n: \nmm\n,\n            \nSourceVariableName\n: \nTWSobs\n,\n            \nSourceVariableUnit\n: \nmm\n,\n            \nSource2sindbadUnit\n: \n*1\n,\n            \nisCategorical\n: false,\n            \nNameShort\n: \nTWSobs\n,\n            \nSpaceTimeType\n: \nnormal\n,\n            \nSourceDataProductName\n: \nGRACE mascon\n,\n            \nDataPath\n: \ntestInput_TWSmodel/ExpStruct_1000pix_10years_test.mat\n,\n            \nVariableUncertainty\n: {\n                \nData\n: {\n                    \nDataPath\n: \ntestInput_TWSmodel/ExpStruct_1000pix_10years_test.mat\n,\n                    \nfunName\n: \nreadExpStructConstraintsUncert\n,\n                    \nSourceVariableName\n: \nTWSobs_uncert\n\n                    },\n                \nfunName\n: \n,\n                \nconstValue\n : []\n            }\n}\n\n\n\n\n\nIn all the configuration files, comments can be added as follows.\n\n\n\n\n\n\nAdd a top-level field of json with the name/key as 'Numeric.c',\n    where numeric represents the comment number (can be any number but\n    try to keep it to less than 9 comments in a single file), and .c is\n    the identifier for the comment in the json parser (e.g.,\n    readConfigFiles.m).\n\n\n\n\nFor example, if you have three comments in a json file with\n    fields/keys 1.c, 2.c, and 3.c. While reading, the comments are\n    put in as values of above fields.\n\n\n\n\n\n\n\n\n{\n    \n1.c\n:                      \nThis json defines the settings for running SINDBAD by setting 1) time period and paths 2) directory for saving generated code and info\n, \n    \n2.c\n:                      \n3) flags for running optimization (runOpti), generate code (genCode), running generated code (true), reduce memory usage by defining \n,\n    \n3.c\n:                      \nvariables in only one time step (genRedMemCode), and check water and carbon balance and data sanity, 4) rules for array precision during model run\n,\n}\n\n\n\n\n\n\n\n\nNote that these comments are just to make the configuration file\n    intuitive and self-explanatory.\n\n\n\n\n\n\nWhen these conventions are followed, they are not stored in the\n    'info' structure while running SINDBAD.", 
            "title": "Configuration Files"
        }, 
        {
            "location": "/configuration/#experiment", 
            "text": "The central configuration file for a simulation is the  experiment\n    file   [experiment*.json] , which lists the paths to the individual configuration files.  {\n     name :  FluxnetSiteOptimization ,\n     domain :  FR-Hes ,\n     configFiles : {\n         forcing        :  settings/runOpti/forcing.json ,\n         modelStructure :  settings/runOpti/modelStructure_cCycle_CASA.json ,\n         constants      :  settings/runOpti/constants.json ,\n         modelRun       :  settings/runOpti/modelRun.json ,\n         output         :  settings/runOpti/output.json ,\n         spinup         :  settings/runOpti/spinup.json ,\n         params         :  settings/runOpti/params.json ,\n         opti           :  settings/runOpti/opti.json \n    },\n     outputInfoFile :  sandbox/sb_runOpti/FR-Hes/FluxnetSiteOptimizationInfo4FR-Hes.json ,\n     outputDirPath  :  sandbox/sb_runOpti/FR-Hes/ \n}", 
            "title": "experiment"
        }, 
        {
            "location": "/configuration/#forcing", 
            "text": "contains the information related to each forcing\n    variable as well as the name of the function to read the forcing\n    data files and put the data in SINDBAD structure  f .  {\n     funName : {\n         import :  readExpStruct ,\n         check :  checkInputData \n    },\n     Comments :  to get forcing from ExpStruct of TWS model ,\n     size : [Inf, Inf],\n     VariableNames : [ LAI , Rn ,  Rain ,  Snow ,  Tair ,  TairDay ,  PsurfDay , PET ],\n     LAI : {\n         VariableUnit :  m2 m-2 ,\n         SourceVariableName :  LAI ,\n         SourceVariableUnit :  m2 m-2 ,\n         Source2sindbadUnit :  *1 ,\n         isCategorical : false,\n         NameShort :  LAI ,\n         SpaceTimeType :  normal ,\n         SourceDataProductName :  dummy ,\n         DataPath :  input/testInput_TWSmodel/ExpStruct_1000pix_10years_test.mat \n    },\n}", 
            "title": "forcing"
        }, 
        {
            "location": "/configuration/#modelstructure", 
            "text": "contains the information related to the selected\n    approaches for the modules, as well as the information related to\n    carbon and water state variables. It also contains the paths for    the modules directory    the core (default is  coreTEM.m )    {\n     paths : \n    {\n         coreTEM :           model/core/coreTEM.m ,\n         modulesDir :        model/modules/ \n    },\n\n     modules : \n    {\n         getStates : \n        {\n             apprName :      getStates_simple ,\n             runFull :      true,\n             use4spinup :   false\n        },\n         cFlowAct :\n        {\n             apprName :      cFlowAct_simple ,\n             runFull :      true,\n             use4spinup :   false\n        },\n    },  \n     states : \n    {\n         w : \n        {\n             pools  : \n            [\n                [ w.Surf ,      1,   zeros ],\n                [ w.Soil ,      1,   zeros ],\n                ...\n            ],\n             combine :      [false, wPools , zeros ]\n        },\n         wd : \n        {\n             pools  : \n            [\n                [ WTD ,         1,   zeros ],\n                [ w.SnowFrac ,  1,   zeros ]\n            ],\n             combine :      [false, wStates , zeros ]\n        },\n         c : \n        {\n         pools  : \n        [\n            [ c.Veg.Root.F ,    1,   zeros ],\n            [ c.Veg.Root.C ,    1,   zeros ],\n            [ c.Veg.Wood ,      1,   zeros ],\n            ...\n        ],\n        }\n    }\n}", 
            "title": "modelStructure"
        }, 
        {
            "location": "/configuration/#constants", 
            "text": "contains a list of physical constants that can be\n    accessed in any function within SINDBAD.  {\n     constants :\n    {\n         G : [0]\n    }\n}", 
            "title": "constants"
        }, 
        {
            "location": "/configuration/#modelrun", 
            "text": "contains configuration for setting up the model,\n    generating the code, and running the model:    Information related to the time period of the model run.    The temporary directory for a SINDBAD simulation ( runDir ).    The paths of the generated core and  precOnce .    If and what checks for carbon and water balance should be done.    The precision of the array (computation) to be used during the\n    SINDBAD simulation.    {\n     time : \n    {\n         step :                  d ,\n         sDate :                 2002-01-01 ,\n         eDate :                 2011-12-31 ,\n         nYears :               [10],\n         nStepsDay :            [1],\n         nStepsYear :           [365]\n    },\n     paths : {\n         runDir :                output/CASA/ ,\n         genCode : \n        {\n             coreTEM :           ,\n             preCompOnce :       \n        }\n    },\n     flags : \n    {\n         forwardRun :           true,\n         runGenCode :           true,\n         genCode :              true,\n         genRedMemCode :        false,\n         runOpti :              false,\n         checks : \n        {\n             massBalance : \n            {\n                 carbon :       false,\n                 water :        false\n            },\n             numeric :          false,\n             bounds :           false\n        }\n    },\n     rules : \n    {\n         arrayPrecision :        single \n    }\n}", 
            "title": "modelRun"
        }, 
        {
            "location": "/configuration/#output", 
            "text": "contains the information on the model output, and the\n    list of variables that should be stored during the model simulation.  {\n     variables : {\n         to : {\n             write : [ s.w.wGW ,  s.w.wSnow ,  s.w.wSoil , s.c.cEco ]\n        }\n    }\n}", 
            "title": "output"
        }, 
        {
            "location": "/configuration/#spinup", 
            "text": "contains the information on how to carry out the spinup,\n    such as number of model years to run, or if the spinup should be\n    loaded from a file, etc.  {\n     sequence : \n    [\n        {\n             funHandleSpin :         runCoreTEM ,\n             funHandleStop :         ,\n             funAddInputs :         [false,false,true],\n             nLoops :               10\n        },\n        {\n             funHandleSpin :         runCoreTEM ,\n             funHandleStop :         ,\n             funAddInputs :         [true,true,false],\n             nLoops : 1\n        }\n    ],\n     paths : \n    {\n         restartFile :               settings/restartFile.xxx \n    },\n     flags : \n    {\n         recycleMSC :               true,\n         runSpinup :                true,\n         loadSpinup :               false\n    }\n}", 
            "title": "spinup"
        }, 
        {
            "location": "/configuration/#opti", 
            "text": "contains information on the optimization, such as the\n    optimization scheme, the parameters to be optimized, a list of\n    observational constraints and a function to read them, etc.  {\n     costFun : {\n         costName :  calcCostTWSPaper ,\n         costFunsFile :  optimization/costFunctions/optionsCostFunctions.json \n    },\n     method : {\n         funName :  cmaes ,\n         defaultOptimOptions :  optimization/optimSchemes/optionsOptimizationSchemes.json \n    },\n     params2opti : [ wSnwFr.CoverParam , ....],\n     checks :  ,\n     constraints : {\n         funName : {\n             import :  readExpStructConstraints ,\n             check :  \n        },\n         Comments :  to get calibration data from ExpStruct of TWS model ,\n         VariableNames : [ TWSobs ,  SWEobs ,  Evapobs ,  Qrobs ],\n         TWSobs : {\n             VariableUnit :  mm ,\n             SourceVariableName :  TWSobs ,\n             SourceVariableUnit :  mm ,\n             Source2sindbadUnit :  *1 ,\n             isCategorical : false,\n             NameShort :  TWSobs ,\n             SpaceTimeType :  normal ,\n             SourceDataProductName :  GRACE mascon ,\n             DataPath :  testInput_TWSmodel/ExpStruct_1000pix_10years_test.mat ,\n             VariableUncertainty : {\n                 Data : {\n                     DataPath :  testInput_TWSmodel/ExpStruct_1000pix_10years_test.mat ,\n                     funName :  readExpStructConstraintsUncert ,\n                     SourceVariableName :  TWSobs_uncert \n                    },\n                 funName :  ,\n                 constValue  : []\n            }\n}  In all the configuration files, comments can be added as follows.    Add a top-level field of json with the name/key as 'Numeric.c',\n    where numeric represents the comment number (can be any number but\n    try to keep it to less than 9 comments in a single file), and .c is\n    the identifier for the comment in the json parser (e.g.,\n    readConfigFiles.m).   For example, if you have three comments in a json file with\n    fields/keys 1.c, 2.c, and 3.c. While reading, the comments are\n    put in as values of above fields.     {\n     1.c :                       This json defines the settings for running SINDBAD by setting 1) time period and paths 2) directory for saving generated code and info , \n     2.c :                       3) flags for running optimization (runOpti), generate code (genCode), running generated code (true), reduce memory usage by defining  ,\n     3.c :                       variables in only one time step (genRedMemCode), and check water and carbon balance and data sanity, 4) rules for array precision during model run ,\n}    Note that these comments are just to make the configuration file\n    intuitive and self-explanatory.    When these conventions are followed, they are not stored in the\n    'info' structure while running SINDBAD.", 
            "title": "opti"
        }, 
        {
            "location": "/optimization/", 
            "text": "Optimization Basics\n\n\nThe SINDBAD framework provides modular functionality to optimize the TEM using different optimization algorithms, cost functions, and data streams. The information related to optimization are identified with the string 'opti' in info.\n\n\n\n\nThe optimization option for an experiment is turned on by setting the runOpti flag to true in modelRun.json file in the settings directory.\n\n\nThe algorithm to use for an experiment is set in opti.json file in the settings directory.\n\n\nThe cost function to use for an experiment is set in opti.json file in the settings directory.\n\n\nThe observation constraints to use for an experiment is also set in opti.json file in the settings directory.\n\n\n\n\nStructure\n\n\nThe functions and library needed to optimize SINBAD are located in optimization directory in the SINDBAD root. This directory should not be used for any user-specific functions and files.\n\n\n.\n\u251c\u2500\u2500 algorithms\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 cmaes\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 cmaes.m\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 options_cmaes.json\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 lsqnonlin\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 options_lsqnonlin.json\n\u251c\u2500\u2500 costFunctions\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 CostMultiConstraint\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 calcCostMultiConstraint.m\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 options_CostMultiConstraint.json\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 CostTWSPaper\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 calcCostTWSPaper.m\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 options_CostTWSPaper.json\n\u251c\u2500\u2500 optimizers\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 optimizeTEM.m\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 optimizeTEM_cmaes.m\n\u2514\u2500\u2500 utils\n    \u2514\u2500\u2500 calcCostTEM.m\n\n\n\n\nAlgorithms\n\n\n\n\nEach algorithm should have a unique directory.\n\n\nDirectory should have the same name as the matlab function for the algorithm.\n\n\nThe directory for an algorithm may have\n\n\nA matlab function for the optimization algorithm\n\n\nA file in json format with the default options with the name as 'options_'[algorithmName].json.\n\n\nboth files are optional in case of inbuilt matlab optimization algorithms or if the optimization is to be run with default options\n.\n\n\n\n\n\n\nThe existing files and directories in the algorithm directory should never be edited, moved, or renamed.\n\n\nAdditional non-default options for an algorithm may be passed to the optimization experiment\n\n\nset the path of another json file (with same format as the default one) in the field nonDefOptFile (under algorithm) in opti.json file in the settings directory.\n\n\nThese user-defined files should be saved in \nother 'user' directories than the algorithms directory under main optimization directory.\n\n\n\n\n\n\n\n\nCost Functions\n\n\n\n\n\n\nLike algorithm, each cost function should have a unique directory.\n\n\n\n\n\n\nDirectory should be named in a logical way [costName] so that it reflects the cost or the study that the cost function is taken from.\n\n\n\n\nThe directory of a cost functions has:\n\n\nA matlab function that calculates the cost. This file is named as calc[CostName].m\n\n\nAn optional file in json format with the default options with the name as 'options_'CostName.json.\n\n\n\n\n\n\n\n\nThe existing files and directories in the costFunctions directory should never be edited, moved, or renamed.\n\n\n\n\n\n\nAdditional non-default options for a cost function may be passed to the optimization experiment\n\n\n\n\nset the path of another json file (with same format as the default one) in the field nonDefOptFile (under costFun) in opti.json file in the settings directory.\n\n\nThese user-defined files should be saved in \nother 'user' directories than the costFunctions directory under main optimization directory.\n\n\n\n\n\n\n\n\nOptimizers\n\n\n\n\nThe optimizer essentially connects the model, data, cost function, and optimization algorithm.\n\n\nEach optimization algorithm can be given an optimizer.\n\n\nThe optimizer should be named as optimizeTEM_[algorithmName].m\n\n\nIf such optimizer function is not provided, the optimizeTEM function is used with default system options of the optimization algorithm.\n\n\n\n\n\n\nThe optimizer calls the optimization algorithm (with user defined options) and passes ir the calcCostTEM function in the utils directory.\n\n\ncalcCostTEM runs the model and calls the cost function (with its options) and evaluates the model cost, which is minimized by the optimization algorithm.\n\n\ncalcCostTEM function should never be edited.\n\n\n\n\n\n\nCreate a copy of the optimizer when a new optimizer for a new optimization algorithm is added.", 
            "title": "SINDBAD Optimization"
        }, 
        {
            "location": "/optimization/#optimization-basics", 
            "text": "The SINDBAD framework provides modular functionality to optimize the TEM using different optimization algorithms, cost functions, and data streams. The information related to optimization are identified with the string 'opti' in info.   The optimization option for an experiment is turned on by setting the runOpti flag to true in modelRun.json file in the settings directory.  The algorithm to use for an experiment is set in opti.json file in the settings directory.  The cost function to use for an experiment is set in opti.json file in the settings directory.  The observation constraints to use for an experiment is also set in opti.json file in the settings directory.", 
            "title": "Optimization Basics"
        }, 
        {
            "location": "/optimization/#structure", 
            "text": "The functions and library needed to optimize SINBAD are located in optimization directory in the SINDBAD root. This directory should not be used for any user-specific functions and files.  .\n\u251c\u2500\u2500 algorithms\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 cmaes\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 cmaes.m\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 options_cmaes.json\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 lsqnonlin\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 options_lsqnonlin.json\n\u251c\u2500\u2500 costFunctions\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 CostMultiConstraint\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 calcCostMultiConstraint.m\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 options_CostMultiConstraint.json\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 CostTWSPaper\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 calcCostTWSPaper.m\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 options_CostTWSPaper.json\n\u251c\u2500\u2500 optimizers\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 optimizeTEM.m\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 optimizeTEM_cmaes.m\n\u2514\u2500\u2500 utils\n    \u2514\u2500\u2500 calcCostTEM.m", 
            "title": "Structure"
        }, 
        {
            "location": "/optimization/#algorithms", 
            "text": "Each algorithm should have a unique directory.  Directory should have the same name as the matlab function for the algorithm.  The directory for an algorithm may have  A matlab function for the optimization algorithm  A file in json format with the default options with the name as 'options_'[algorithmName].json.  both files are optional in case of inbuilt matlab optimization algorithms or if the optimization is to be run with default options .    The existing files and directories in the algorithm directory should never be edited, moved, or renamed.  Additional non-default options for an algorithm may be passed to the optimization experiment  set the path of another json file (with same format as the default one) in the field nonDefOptFile (under algorithm) in opti.json file in the settings directory.  These user-defined files should be saved in  other 'user' directories than the algorithms directory under main optimization directory.", 
            "title": "Algorithms"
        }, 
        {
            "location": "/optimization/#cost-functions", 
            "text": "Like algorithm, each cost function should have a unique directory.    Directory should be named in a logical way [costName] so that it reflects the cost or the study that the cost function is taken from.   The directory of a cost functions has:  A matlab function that calculates the cost. This file is named as calc[CostName].m  An optional file in json format with the default options with the name as 'options_'CostName.json.     The existing files and directories in the costFunctions directory should never be edited, moved, or renamed.    Additional non-default options for a cost function may be passed to the optimization experiment   set the path of another json file (with same format as the default one) in the field nonDefOptFile (under costFun) in opti.json file in the settings directory.  These user-defined files should be saved in  other 'user' directories than the costFunctions directory under main optimization directory.", 
            "title": "Cost Functions"
        }, 
        {
            "location": "/optimization/#optimizers", 
            "text": "The optimizer essentially connects the model, data, cost function, and optimization algorithm.  Each optimization algorithm can be given an optimizer.  The optimizer should be named as optimizeTEM_[algorithmName].m  If such optimizer function is not provided, the optimizeTEM function is used with default system options of the optimization algorithm.    The optimizer calls the optimization algorithm (with user defined options) and passes ir the calcCostTEM function in the utils directory.  calcCostTEM runs the model and calls the cost function (with its options) and evaluates the model cost, which is minimized by the optimization algorithm.  calcCostTEM function should never be edited.    Create a copy of the optimizer when a new optimizer for a new optimization algorithm is added.", 
            "title": "Optimizers"
        }
    ]
}