import{_ as e,c as t,o as s,aA as a}from"./chunks/framework.Cow1Yd9I.js";const k=JSON.parse('{"title":"Machine Learning Methods in SindbadML","description":"","frontmatter":{},"headers":[],"relativePath":"pages/develop/hybrid_modeling.md","filePath":"pages/develop/hybrid_modeling.md","lastUpdated":null}'),n={name:"pages/develop/hybrid_modeling.md"};function l(r,i,o,d,h,p){return s(),t("div",null,[...i[0]||(i[0]=[a(`<h1 id="Machine-Learning-Methods-in-SindbadML" tabindex="-1">Machine Learning Methods in SindbadML <a class="header-anchor" href="#Machine-Learning-Methods-in-SindbadML" aria-label="Permalink to &quot;Machine Learning Methods in SindbadML {#Machine-Learning-Methods-in-SindbadML}&quot;">​</a></h1><p>This page provides an overview of machine learning methods available within SindbadML. It includes details on various components such as activation functions, gradient methods, ML models, optimizers, and training methods, and how to extend them for experiment related to hybrid ML-physical modeling.</p><h1 id="Extending-SindbadML:-How-to-Add-New-Components" tabindex="-1">Extending SindbadML: How to Add New Components <a class="header-anchor" href="#Extending-SindbadML:-How-to-Add-New-Components" aria-label="Permalink to &quot;Extending SindbadML: How to Add New Components {#Extending-SindbadML:-How-to-Add-New-Components}&quot;">​</a></h1><p>This guide shows how to add new <strong>activation functions</strong>, <strong>gradient methods</strong>, <strong>ML models</strong>, <strong>optimizers</strong>, and <strong>training methods</strong> by following the conventions in the <code>src/Types/MLTypes.jl</code> and related files.</p><hr><h2 id="1.-Adding-a-New-Activation-Function" tabindex="-1">1. Adding a New Activation Function <a class="header-anchor" href="#1.-Adding-a-New-Activation-Function" aria-label="Permalink to &quot;1. Adding a New Activation Function {#1.-Adding-a-New-Activation-Function}&quot;">​</a></h2><h3 id="Step-1:-Define-the-Activation-Type" tabindex="-1">Step 1: Define the Activation Type <a class="header-anchor" href="#Step-1:-Define-the-Activation-Type" aria-label="Permalink to &quot;Step 1: Define the Activation Type {#Step-1:-Define-the-Activation-Type}&quot;">​</a></h3><p>In <code>src/Types/MLTypes.jl</code>, add a new struct subtype of <code>ActivationType</code> and export it:</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> MyActivation</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">struct</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> MyActivation </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> ActivationType</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> end</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">purpose</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Type{MyActivation}</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;Describe your activation function here&quot;</span></span></code></pre></div><h3 id="Step-2:-Implement-the-Activation-Function" tabindex="-1">Step 2: Implement the Activation Function <a class="header-anchor" href="#Step-2:-Implement-the-Activation-Function" aria-label="Permalink to &quot;Step 2: Implement the Activation Function {#Step-2:-Implement-the-Activation-Function}&quot;">​</a></h3><p>In <code>lib/SindbadML/src/activationFunctions.jl</code>, extend <code>activationFunction</code>:</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">function</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> activationFunction</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(model_options, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">MyActivation</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # Example: Swish activation</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">    swish</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(x) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Flux</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">sigmoid</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(x)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> swish</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">end</span></span></code></pre></div><hr><h2 id="2.-Adding-a-New-Gradient-Method" tabindex="-1">2. Adding a New Gradient Method <a class="header-anchor" href="#2.-Adding-a-New-Gradient-Method" aria-label="Permalink to &quot;2. Adding a New Gradient Method {#2.-Adding-a-New-Gradient-Method}&quot;">​</a></h2><h3 id="Step-1:-Define-the-Gradient-Type" tabindex="-1">Step 1: Define the Gradient Type <a class="header-anchor" href="#Step-1:-Define-the-Gradient-Type" aria-label="Permalink to &quot;Step 1: Define the Gradient Type {#Step-1:-Define-the-Gradient-Type}&quot;">​</a></h3><p>In <code>src/Types/MLTypes.jl</code>, add and export your new gradient type:</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> MyGradMethod</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">struct</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> MyGradMethod </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> MLGradType</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> end</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">purpose</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Type{MyGradMethod}</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;Describe your gradient method&quot;</span></span></code></pre></div><h3 id="Step-2:-Implement-the-Gradient-Logic" tabindex="-1">Step 2: Implement the Gradient Logic <a class="header-anchor" href="#Step-2:-Implement-the-Gradient-Logic" aria-label="Permalink to &quot;Step 2: Implement the Gradient Logic {#Step-2:-Implement-the-Gradient-Logic}&quot;">​</a></h3><p>In <code>lib/SindbadML/src/mlGradient.jl</code>, extend <code>gradientSite</code> and/or <code>gradientBatch!</code>:</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">function</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> gradientSite</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">MyGradMethod</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, x_vals</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">AbstractArray</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, gradient_options</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">NamedTuple</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, loss_f</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">F</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">where</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> {F}</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # Implement your gradient calculation here</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> my_gradient</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(x_vals, loss_f)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">end</span></span></code></pre></div><hr><h2 id="3.-Adding-a-New-ML-Model" tabindex="-1">3. Adding a New ML Model <a class="header-anchor" href="#3.-Adding-a-New-ML-Model" aria-label="Permalink to &quot;3. Adding a New ML Model {#3.-Adding-a-New-ML-Model}&quot;">​</a></h2><h3 id="Step-1:-Define-the-Model-Type" tabindex="-1">Step 1: Define the Model Type <a class="header-anchor" href="#Step-1:-Define-the-Model-Type" aria-label="Permalink to &quot;Step 1: Define the Model Type {#Step-1:-Define-the-Model-Type}&quot;">​</a></h3><p>In <code>src/Types/MLTypes.jl</code>, add and export your new model type:</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> MyMLModel</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">struct</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> MyMLModel </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> MLModelType</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> end</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">purpose</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Type{MyMLModel}</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;Describe your ML model&quot;</span></span></code></pre></div><h3 id="Step-2:-Implement-the-Model-Constructor" tabindex="-1">Step 2: Implement the Model Constructor <a class="header-anchor" href="#Step-2:-Implement-the-Model-Constructor" aria-label="Permalink to &quot;Step 2: Implement the Model Constructor {#Step-2:-Implement-the-Model-Constructor}&quot;">​</a></h3><p>In <code>lib/SindbadML/src/mlModels.jl</code>, extend <code>mlModel</code>:</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">function</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> mlModel</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(info, n_features, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">MyMLModel</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # Build and return your model</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> MyModelConstructor</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(n_features, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">...</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">end</span></span></code></pre></div><hr><h2 id="4.-Adding-a-New-Optimizer" tabindex="-1">4. Adding a New Optimizer <a class="header-anchor" href="#4.-Adding-a-New-Optimizer" aria-label="Permalink to &quot;4. Adding a New Optimizer {#4.-Adding-a-New-Optimizer}&quot;">​</a></h2><h3 id="Step-1:-Define-the-Optimizer-Type" tabindex="-1">Step 1: Define the Optimizer Type <a class="header-anchor" href="#Step-1:-Define-the-Optimizer-Type" aria-label="Permalink to &quot;Step 1: Define the Optimizer Type {#Step-1:-Define-the-Optimizer-Type}&quot;">​</a></h3><p>In <code>src/Types/MLTypes.jl</code>, add and export your optimizer type:</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> MyOptimizer</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">struct</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> MyOptimizer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> MLOptimizerType</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> end</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">purpose</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Type{MyOptimizer}</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;Describe your optimizer&quot;</span></span></code></pre></div><h3 id="Step-2:-Implement-the-Optimizer-Constructor" tabindex="-1">Step 2: Implement the Optimizer Constructor <a class="header-anchor" href="#Step-2:-Implement-the-Optimizer-Constructor" aria-label="Permalink to &quot;Step 2: Implement the Optimizer Constructor {#Step-2:-Implement-the-Optimizer-Constructor}&quot;">​</a></h3><p>In <code>lib/SindbadML/src/mlOptimizers.jl</code>, extend <code>mlOptimizer</code>:</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">function</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> mlOptimizer</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(optimizer_options, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">MyOptimizer</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # Return an optimizer object</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> MyOptimizerConstructor</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(optimizer_options</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">...</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">end</span></span></code></pre></div><hr><h2 id="5.-Adding-a-New-Training-Method" tabindex="-1">5. Adding a New Training Method <a class="header-anchor" href="#5.-Adding-a-New-Training-Method" aria-label="Permalink to &quot;5. Adding a New Training Method {#5.-Adding-a-New-Training-Method}&quot;">​</a></h2><h3 id="Step-1:-Define-the-Training-Type" tabindex="-1">Step 1: Define the Training Type <a class="header-anchor" href="#Step-1:-Define-the-Training-Type" aria-label="Permalink to &quot;Step 1: Define the Training Type {#Step-1:-Define-the-Training-Type}&quot;">​</a></h3><p>In <code>src/Types/MLTypes.jl</code>, add and export your training type:</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> MyTrainingMethod</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">struct</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> MyTrainingMethod </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> MLTrainingType</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> end</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">purpose</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Type{MyTrainingMethod}</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;Describe your training method&quot;</span></span></code></pre></div><h3 id="Step-2:-Implement-the-Training-Function" tabindex="-1">Step 2: Implement the Training Function <a class="header-anchor" href="#Step-2:-Implement-the-Training-Function" aria-label="Permalink to &quot;Step 2: Implement the Training Function {#Step-2:-Implement-the-Training-Function}&quot;">​</a></h3><p>In <code>lib/SindbadML/src/mlTrain.jl</code>, extend <code>trainML</code>:</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">function</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> trainML</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(hybrid_helpers, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">MyTrainingMethod</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # Implement your training loop here</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">end</span></span></code></pre></div><hr><h2 id="6.-Register-and-Use-Your-New-Types" tabindex="-1">6. Register and Use Your New Types <a class="header-anchor" href="#6.-Register-and-Use-Your-New-Types" aria-label="Permalink to &quot;6. Register and Use Your New Types {#6.-Register-and-Use-Your-New-Types}&quot;">​</a></h2><ul><li><p><strong>Export</strong> your new types in <code>MLTypes.jl</code>.</p></li><li><p>Reference your new types in experiment or parameter JSON files (e.g., <code>&quot;activation_out&quot;: &quot;my_activation&quot;</code>).</p></li><li><p>Make sure your new types are imported where needed.</p></li></ul><hr><h2 id="Summary-Table" tabindex="-1">Summary Table <a class="header-anchor" href="#Summary-Table" aria-label="Permalink to &quot;Summary Table {#Summary-Table}&quot;">​</a></h2><table tabindex="0"><thead><tr><th style="text-align:right;">Component</th><th style="text-align:right;">Abstract Type</th><th style="text-align:right;">File(s) to Edit</th><th style="text-align:right;">Function to Extend</th></tr></thead><tbody><tr><td style="text-align:right;">Activation</td><td style="text-align:right;"><code>ActivationType</code></td><td style="text-align:right;"><code>MLTypes.jl</code>, <code>activationFunctions.jl</code></td><td style="text-align:right;"><code>activationFunction</code></td></tr><tr><td style="text-align:right;">Gradient Method</td><td style="text-align:right;"><code>MLGradType</code></td><td style="text-align:right;"><code>MLTypes.jl</code>, <code>mlGradient.jl</code></td><td style="text-align:right;"><code>gradientSite</code>, <code>gradientBatch!</code></td></tr><tr><td style="text-align:right;">ML Model</td><td style="text-align:right;"><code>MLModelType</code></td><td style="text-align:right;"><code>MLTypes.jl</code>, <code>mlModels.jl</code></td><td style="text-align:right;"><code>mlModel</code></td></tr><tr><td style="text-align:right;">Optimizer</td><td style="text-align:right;"><code>MLOptimizerType</code></td><td style="text-align:right;"><code>MLTypes.jl</code>, <code>mlOptimizers.jl</code></td><td style="text-align:right;"><code>mlOptimizer</code></td></tr><tr><td style="text-align:right;">Training Method</td><td style="text-align:right;"><code>MLTrainingType</code></td><td style="text-align:right;"><code>MLTypes.jl</code>, <code>mlTrain.jl</code></td><td style="text-align:right;"><code>trainML</code></td></tr></tbody></table><hr><p><strong>Tip:</strong> Always add a <code>purpose(::Type{YourType})</code> method for documentation and introspection. <strong>Tip:</strong> Export your new types for use in other modules.</p><p>For more examples, see the existing code in the referenced files.</p><h1 id="SINDBAD-Hybrid-ML-Experiment-Outputs" tabindex="-1">SINDBAD Hybrid ML Experiment Outputs <a class="header-anchor" href="#SINDBAD-Hybrid-ML-Experiment-Outputs" aria-label="Permalink to &quot;SINDBAD Hybrid ML Experiment Outputs {#SINDBAD-Hybrid-ML-Experiment-Outputs}&quot;">​</a></h1><p>This document describes the outputs generated by SINDBAD experiments, with a focus on hybrid and machine learning (ML) workflows and its ouptu in <code>JLD2</code> format. The outputs are produced during and after training and evaluation, and are essential for analysis, checkpointing, and reproducibility.</p><div class="info custom-block"><p class="custom-block-title">INFO</p><p>During the REPL run of the trainML, all the outputs are stored in memory in place in <code>hybrid_helpers</code> NamedTuple. These can be dirrectly accessed through <code>hybrid_helpers.loss_array.training</code> etc. However, they are not saved to disk unless explicitly requested via the <code>save_checkpoint</code> option in the experiment config.</p></div><hr><h2 id="1.-Checkpoint-Files" tabindex="-1">1. Checkpoint Files <a class="header-anchor" href="#1.-Checkpoint-Files" aria-label="Permalink to &quot;1. Checkpoint Files {#1.-Checkpoint-Files}&quot;">​</a></h2><p>During training, SINDBAD saves checkpoint files at the end of each epoch (if <code>checkpoint_path</code> is specified). These files are typically stored in JLD2 format and named as <code>epoch_&lt;epoch_number&gt;.jld2</code>.</p><h3 id="Contents-of-Each-Checkpoint-File" tabindex="-1">Contents of Each Checkpoint File <a class="header-anchor" href="#Contents-of-Each-Checkpoint-File" aria-label="Permalink to &quot;Contents of Each Checkpoint File {#Contents-of-Each-Checkpoint-File}&quot;">​</a></h3><p>Each checkpoint file contains the following variables:</p><ul><li><p><code>lower_bound</code>: Lower bounds for each parameter (from the parameter table).</p></li><li><p><code>upper_bound</code>: Upper bounds for each parameter.</p></li><li><p><code>parameter_names</code>: Names of the parameters being learned.</p></li><li><p><code>parameter_table</code>: The full parameter table used for training.</p></li><li><p><code>metadata_global</code>: Global metadata from the experiment configuration (e.g., site info, variable names).</p></li><li><p><code>loss_array_training</code>: Array of scalar loss values for the training set at the current epoch. <strong>Shape:</strong> (number of training sites, 1)</p></li><li><p><code>loss_array_validation</code>: Array of scalar loss values for the validation set at the current epoch. <strong>Shape:</strong> (number of validation sites, 1)</p></li><li><p><code>loss_array_testing</code>: Array of scalar loss values for the testing set at the current epoch. <strong>Shape:</strong> (number of testing sites, 1)</p></li><li><p><code>loss_array_components_training</code>: Array of loss component vectors for the training set at the current epoch. <strong>Shape:</strong> (number of training sites, number of components, 1)</p></li><li><p><code>loss_array_components_validation</code>: Array of loss component vectors for the validation set at the current epoch. <strong>Shape:</strong> (number of validation sites, number of components, 1)</p></li><li><p><code>loss_array_components_testing</code>: Array of loss component vectors for the testing set at the current epoch. <strong>Shape:</strong> (number of testing sites, number of components, 1)</p></li><li><p><code>re</code>: The function to reconstruct the model parameters from the flat vector (for Flux/Optimisers).</p></li><li><p><code>flat</code>: The current flat vector of model parameters (weights).</p></li></ul><hr><h2 id="2.-Loss-Arrays" tabindex="-1">2. Loss Arrays <a class="header-anchor" href="#2.-Loss-Arrays" aria-label="Permalink to &quot;2. Loss Arrays {#2.-Loss-Arrays}&quot;">​</a></h2><p>Loss arrays are stored in memory during training and saved to checkpoint files. They track the evolution of the loss for each site and epoch.</p><ul><li><p><code>loss_array.training</code>: Matrix of scalar loss values for all training sites and epochs. <strong>Shape:</strong> (number of training sites, number of epochs)</p></li><li><p><code>loss_array.validation</code>: Matrix of scalar loss values for all validation sites and epochs. <strong>Shape:</strong> (number of validation sites, number of epochs)</p></li><li><p><code>loss_array.testing</code>: Matrix of scalar loss values for all testing sites and epochs. <strong>Shape:</strong> (number of testing sites, number of epochs)</p></li></ul><p>Component-wise loss arrays:</p><ul><li><p><code>loss_array_components.training</code>: 3D array of loss components for training sites and epochs. <strong>Shape:</strong> (number of training sites, number of components, number of epochs)</p></li><li><p><code>loss_array_components.validation</code>: 3D array of loss components for validation sites and epochs. <strong>Shape:</strong> (number of validation sites, number of components, number of epochs)</p></li><li><p><code>loss_array_components.testing</code>: 3D array of loss components for testing sites and epochs. <strong>Shape:</strong> (number of testing sites, number of components, number of epochs)</p></li></ul><hr><h2 id="3.-Model-Parameters" tabindex="-1">3. Model Parameters <a class="header-anchor" href="#3.-Model-Parameters" aria-label="Permalink to &quot;3. Model Parameters {#3.-Model-Parameters}&quot;">​</a></h2><ul><li><p><code>flat</code>: The current flat vector of all model parameters (weights).</p></li><li><p><code>re</code>: The function to reconstruct the full model (e.g., Flux neural network) from the flat parameter vector.</p></li></ul><p>These are used for resuming training, model evaluation, or exporting the trained model.</p><hr><h2 id="4.-Metadata" tabindex="-1">4. Metadata <a class="header-anchor" href="#4.-Metadata" aria-label="Permalink to &quot;4. Metadata {#4.-Metadata}&quot;">​</a></h2><ul><li><p><code>parameter_table</code>: The full parameter table, including bounds, names, and other metadata.</p></li><li><p><code>metadata_global</code>: Experiment-wide metadata, such as site information, variable names, and configuration details.</p></li></ul><hr><h2 id="5.-Additional-Outputs" tabindex="-1">5. Additional Outputs <a class="header-anchor" href="#5.-Additional-Outputs" aria-label="Permalink to &quot;5. Additional Outputs {#5.-Additional-Outputs}&quot;">​</a></h2><p>Depending on the experiment and configuration, additional outputs may include:</p><ul><li><p><strong>Predictions:</strong> Model predictions for each site and time step (if saved).</p></li><li><p><strong>Best Model:</strong> The parameters or checkpoint corresponding to the best validation loss (if tracked).</p></li><li><p><strong>Diagnostics:</strong> Any additional diagnostic arrays or logs produced during training or evaluation.</p></li></ul><hr><h2 id="Example:-Accessing-Output-Variables" tabindex="-1">Example: Accessing Output Variables <a class="header-anchor" href="#Example:-Accessing-Output-Variables" aria-label="Permalink to &quot;Example: Accessing Output Variables {#Example:-Accessing-Output-Variables}&quot;">​</a></h2><p>To load a checkpoint and access its contents in Julia:</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">using</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> JLD2</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">data </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> jldopen</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;epoch_10.jld2&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;r&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">do</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> file</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    Dict</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(name </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> read</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(file, name) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> name </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> keys</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(file))</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">end</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Example: Access training loss for epoch 10</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">training_loss </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> data[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;loss_array_training&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span></code></pre></div><h4 id="Summary-Table-2" tabindex="-1">Summary Table <a class="header-anchor" href="#Summary-Table-2" aria-label="Permalink to &quot;Summary Table {#Summary-Table-2}&quot;">​</a></h4><table tabindex="0"><thead><tr><th style="text-align:right;">Variable Name</th><th style="text-align:right;">Description</th><th style="text-align:right;">Shape / Type</th></tr></thead><tbody><tr><td style="text-align:right;"><code>lower_bound</code></td><td style="text-align:right;">Lower bounds for parameters</td><td style="text-align:right;">Vector (n_params)</td></tr><tr><td style="text-align:right;"><code>upper_bound</code></td><td style="text-align:right;">Upper bounds for parameters</td><td style="text-align:right;">Vector (n_params)</td></tr><tr><td style="text-align:right;"><code>parameter_names</code></td><td style="text-align:right;">Names of parameters</td><td style="text-align:right;">Vector (n_params)</td></tr><tr><td style="text-align:right;"><code>parameter_table</code></td><td style="text-align:right;">Full parameter table</td><td style="text-align:right;">Table / NamedTuple</td></tr><tr><td style="text-align:right;"><code>metadata_global</code></td><td style="text-align:right;">Global experiment metadata</td><td style="text-align:right;">NamedTuple / Dict</td></tr><tr><td style="text-align:right;"><code>loss_array_training</code></td><td style="text-align:right;">Training loss (scalar) for current epoch</td><td style="text-align:right;">Matrix (n_train_sites, 1)</td></tr><tr><td style="text-align:right;"><code>loss_array_validation</code></td><td style="text-align:right;">Validation loss (scalar) for current epoch</td><td style="text-align:right;">Matrix (n_val_sites, 1)</td></tr><tr><td style="text-align:right;"><code>loss_array_testing</code></td><td style="text-align:right;">Testing loss (scalar) for current epoch</td><td style="text-align:right;">Matrix (n_test_sites, 1)</td></tr><tr><td style="text-align:right;"><code>loss_array_components_training</code></td><td style="text-align:right;">Training loss components for current epoch</td><td style="text-align:right;">Array (n_train_sites, n_comp, 1)</td></tr><tr><td style="text-align:right;"><code>loss_array_components_validation</code></td><td style="text-align:right;">Validation loss components for current epoch</td><td style="text-align:right;">Array (n_val_sites, n_comp, 1)</td></tr><tr><td style="text-align:right;"><code>loss_array_components_testing</code></td><td style="text-align:right;">Testing loss components for current epoch</td><td style="text-align:right;">Array (n_test_sites, n_comp, 1)</td></tr><tr><td style="text-align:right;"><code>re</code></td><td style="text-align:right;">Function to reconstruct model from flat parameters</td><td style="text-align:right;">Function</td></tr><tr><td style="text-align:right;"><code>flat</code></td><td style="text-align:right;">Flat vector of model parameters</td><td style="text-align:right;">Vector (n_weights)</td></tr></tbody></table>`,85)])])}const g=e(n,[["render",l]]);export{k as __pageData,g as default};
